#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†ææ¨¡å—

åŸºäºçˆ¶è¯„è®ºå’Œå­è¯„è®ºçš„æƒ…æ„Ÿå·®å¼‚åˆ†æä»ä¼—å¿ƒç†ç‰¹å¾
é€šè¿‡é˜¿é‡Œäº‘APIè®¡ç®—æƒ…æ„Ÿå€¼ï¼Œåˆ†ææƒ…æ„Ÿç›¸ä¼¼æ€§
"""

import os
import sys
import json
import time
import threading
import argparse
import logging
from datetime import datetime
from typing import Dict, List, Union, Optional
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from text_analysis.core.base_analyzer import BaseAnalyzer, create_parser, parse_common_args
from text_analysis.core.aliyun_api_manager import get_aliyun_api_manager, is_aliyun_api_available
from text_analysis.algorithms.normalization import MinMaxNormalizer

import pandas as pd
import numpy as np

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SentimentConformityAnalyzer(BaseAnalyzer):
    """æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æå™¨"""
    
    def __init__(self, module_name: str = "sentiment_conformity_analyzer", 
                 video_id: Optional[str] = None, output_dir: Optional[str] = None, **kwargs):
        """åˆå§‹åŒ–æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æå™¨"""
        super().__init__(module_name=module_name, **kwargs)
        self.output_dir = output_dir or os.path.join(os.getcwd(), "output")
        self.normalizer = MinMaxNormalizer(feature_range=(0, 1))
        self.results = {}
        
        # åˆå§‹åŒ–é˜¿é‡Œäº‘APIç®¡ç†å™¨
        self.api_manager = get_aliyun_api_manager()
        if not self.api_manager:
            raise ValueError("é˜¿é‡Œäº‘APIé…ç½®ç¼ºå¤±ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡")
        
        # å¹¶å‘æ§åˆ¶å‚æ•°
        self.sa_concurrency = kwargs.get('sa_concurrency', 8)
        self.sa_batch_size = kwargs.get('sa_batch_size', 200)
        self.sa_throttle_ms = kwargs.get('sa_throttle_ms', 0)
        self._stats_lock = threading.Lock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_analyzed': 0,
            'parent_comments': 0,
            'child_comments': 0,
            'api_calls': 0,
            'api_errors': 0,
            'total_confidence': 0.0,
            'total_sentiment_score': 0.0
        }
    
    def analyze_sentiment(self, text: str) -> Dict[str, Union[str, float]]:
        """
        ä½¿ç”¨é˜¿é‡Œäº‘APIåˆ†ææ–‡æœ¬æƒ…æ„Ÿ
        
        Args:
            text: å¾…åˆ†æçš„æ–‡æœ¬
            
        Returns:
            Dict: åŒ…å«æƒ…æ„Ÿåˆ†æç»“æœçš„å­—å…¸
        """
        if not text or not text.strip():
            return {
                'sentiment': 'neutral',
                'score': 0.0,
                'confidence': 0.0,
                'method': 'aliyun'
            }
        
        try:
            result = self.api_manager.analyze_sentiment(text)
            
            with self._stats_lock:
                self.stats['api_calls'] += 1
                self.stats['total_confidence'] += result.get('confidence', 0.0)
                self.stats['total_sentiment_score'] += result.get('score', 0.0)
            
            return {
                'sentiment': result['sentiment'],
                'score': result['score'],
                'confidence': result['confidence'],
                'method': 'aliyun'
            }
        except Exception as e:
            logger.error(f"é˜¿é‡Œäº‘æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            with self._stats_lock:
                self.stats['api_errors'] += 1
            
            return {
                'sentiment': 'neutral',
                'score': 0.0,
                'confidence': 0.0,
                'error': str(e),
                'method': 'aliyun'
            }
    
    def _analyze_texts_concurrent(self, texts: List[str]) -> List[Dict[str, Union[str, float]]]:
        """å¹¶å‘æ‰¹é‡æƒ…æ„Ÿåˆ†æ"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        n = len(texts)
        if n == 0:
            return []
        
        # å»é‡æ˜ å°„
        unique_index: Dict[str, int] = {}
        order_to_text: Dict[int, str] = {}
        for i, t in enumerate(texts):
            if t not in unique_index:
                unique_index[t] = len(unique_index)
            order_to_text[i] = t
        
        unique_list: List[str] = [None] * len(unique_index)
        for t, u in unique_index.items():
            unique_list[u] = t
        
        unique_results: List[Dict[str, Union[str, float]]] = [None] * len(unique_list)
        
        def _process_range(start: int, end: int):
            logger.info(f"æƒ…æ„ŸAPI {start+1}-{end}/{len(unique_list)}")
            with ThreadPoolExecutor(max_workers=self.sa_concurrency) as ex:
                futures = {}
                for idx in range(start, end):
                    # å¯é€‰èŠ‚æµ
                    if self.sa_throttle_ms > 0 and (idx - start) % self.sa_concurrency == 0:
                        time.sleep(self.sa_throttle_ms / 1000.0)
                    futures[ex.submit(self.analyze_sentiment, unique_list[idx])] = idx
                
                for fut in as_completed(futures):
                    uid = futures[fut]
                    try:
                        unique_results[uid] = fut.result()
                    except Exception as e:
                        unique_results[uid] = {
                            'sentiment': 'neutral', 'score': 0.0, 'confidence': 0.0,
                            'error': str(e), 'method': 'aliyun'
                        }
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(unique_list), self.sa_batch_size):
            _process_range(i, min(i + self.sa_batch_size, len(unique_list)))
        
        # å›å¡«ç»“æœ
        result_map: Dict[str, Dict[str, Union[str, float]]] = {
            t: unique_results[u] for t, u in unique_index.items()
        }
        return [result_map[order_to_text[i]] for i in range(n)]
    
    def calculate_sentiment_conformity_score(self, data: Union[pd.DataFrame, List[Dict]]) -> Union[pd.DataFrame, List[Dict]]:
        """
        è®¡ç®—æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°
        
        Args:
            data: åŒ…å«è¯„è®ºæ•°æ®çš„DataFrameæˆ–å­—å…¸åˆ—è¡¨ï¼Œéœ€è¦åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                - content: è¯„è®ºå†…å®¹
                - comment_id: è¯„è®ºID
                - is_parent: çˆ¶è¯„è®ºæ ‡è¯†ï¼ˆå¯é€‰ï¼Œå¦‚æœæ•°æ®å·²é€šè¿‡æ•°æ®æ¸…æ´—æ¨¡å—å¤„ç†ï¼‰
                
        Returns:
            Union[pd.DataFrame, List[Dict]]: åŒ…å«æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°çš„æ•°æ®
        """
        logger.info("å¼€å§‹è®¡ç®—æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°...")
        
        # å¤„ç†è¾“å…¥æ•°æ®æ ¼å¼
        if isinstance(data, list):
            df = pd.DataFrame(data)
            return_dict = True
        else:
            df = data.copy()
            return_dict = False
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å·²ç»è¿‡å¤„ç†
        if 'is_parent' in df.columns:
            logger.info("æ£€æµ‹åˆ°å·²å¤„ç†çš„æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨")
        else:
            logger.info("æ•°æ®æœªç»è¿‡å¤„ç†ï¼Œå¼€å§‹å¤„ç†...")
            
            # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
            if 'content' not in df.columns:
                raise ValueError("æ•°æ®ä¸­ç¼ºå°‘contentå­—æ®µ")
            if 'comment_id' not in df.columns:
                raise ValueError("æ•°æ®ä¸­ç¼ºå°‘comment_idå­—æ®µ")
            
            # å‡è®¾ç¬¬ä¸€ä¸ªè¯„è®ºæ˜¯çˆ¶è¯„è®º
            df['is_parent'] = False
            df.loc[0, 'is_parent'] = True
            logger.info("å‡è®¾ç¬¬ä¸€ä¸ªè¯„è®ºä¸ºçˆ¶è¯„è®º")
        
        # åˆ†ç¦»çˆ¶è¯„è®ºå’Œå­è¯„è®º
        parent_data = df[df['is_parent'] == True]
        child_data = df[df['is_parent'] == False]
        
        if len(parent_data) == 0:
            raise ValueError("æœªæ‰¾åˆ°çˆ¶è¯„è®ºæ•°æ®")
        
        parent_comment = parent_data.iloc[0]
        parent_id = parent_comment['comment_id']
        parent_content = parent_comment['content']
        
        logger.info(f"çˆ¶è¯„è®ºID: {parent_id}")
        logger.info(f"å­è¯„è®ºæ•°é‡: {len(child_data)}")
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦åˆ†æçš„æ–‡æœ¬
        all_texts = [parent_content]
        for _, row in child_data.iterrows():
            all_texts.append(row['content'])
        
        # å¹¶å‘è¿›è¡Œæƒ…æ„Ÿåˆ†æ
        logger.info("å¼€å§‹å¹¶å‘æƒ…æ„Ÿåˆ†æ...")
        sentiment_results = self._analyze_texts_concurrent(all_texts)
        
        # æå–çˆ¶è¯„è®ºæƒ…æ„Ÿç»“æœ
        parent_sentiment = sentiment_results[0]
        parent_score = parent_sentiment['score']
        parent_sentiment_type = parent_sentiment['sentiment']
        
        logger.info(f"çˆ¶è¯„è®ºæƒ…æ„Ÿ: {parent_sentiment_type}, åˆ†æ•°: {parent_score:.4f}")
        
        # è®¡ç®—æ¯ä¸ªå­è¯„è®ºçš„æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°
        sentiment_differences = []
        conformity_scores = []
        
        for i, (_, row) in enumerate(child_data.iterrows()):
            child_sentiment = sentiment_results[i + 1]  # +1 å› ä¸ºç¬¬ä¸€ä¸ªæ˜¯çˆ¶è¯„è®º
            child_score = child_sentiment['score']
            
            # è®¡ç®—æƒ…æ„Ÿå·®å¼‚çš„ç»å¯¹å€¼
            sentiment_diff = abs(parent_score - child_score)
            sentiment_differences.append(sentiment_diff)
        
        # è®¡ç®—è‡ªé€‚åº”å½’ä¸€åŒ–å‚æ•°
        if sentiment_differences:
            # ä½¿ç”¨ä¸­ä½æ•°ä½œä¸ºå‚è€ƒç‚¹
            median_diff = np.median(sentiment_differences)
            max_diff = np.max(sentiment_differences)
            
            # å¦‚æœå·®å¼‚èŒƒå›´å¾ˆå¤§ï¼Œä½¿ç”¨å¯¹æ•°ç¼©æ”¾
            if max_diff > median_diff * 10:
                # ä½¿ç”¨å¯¹æ•°ç¼©æ”¾å¤„ç†å¤§èŒƒå›´å·®å¼‚
                log_differences = [np.log1p(diff) for diff in sentiment_differences]
                normalized_scores = self.normalizer.fit_transform(
                    np.array(log_differences).reshape(-1, 1)
                ).flatten()
                conformity_scores = 1 - normalized_scores
                logger.info("ä½¿ç”¨å¯¹æ•°ç¼©æ”¾å¤„ç†å¤§èŒƒå›´æƒ…æ„Ÿå·®å¼‚")
            else:
                # ç›´æ¥å½’ä¸€åŒ–å·®å¼‚
                normalized_scores = self.normalizer.fit_transform(
                    np.array(sentiment_differences).reshape(-1, 1)
                ).flatten()
                conformity_scores = 1 - normalized_scores
                logger.info("ä½¿ç”¨ç›´æ¥å½’ä¸€åŒ–å¤„ç†æƒ…æ„Ÿå·®å¼‚")
        else:
            logger.warning("æœªæ‰¾åˆ°å­è¯„è®ºæ•°æ®")
            conformity_scores = []
        
        # ä¸ºçˆ¶è¯„è®ºæ·»åŠ åˆ†æ•°ï¼ˆè®¾ä¸º1.0ï¼Œè¡¨ç¤ºå®Œå…¨ä»ä¼—ï¼‰
        parent_conformity_score = 1.0
        
        # å°†ç»“æœæ·»åŠ åˆ°DataFrame
        df['sentiment_difference'] = 0.0  # çˆ¶è¯„è®ºçš„å·®å¼‚ä¸º0
        df['raw_sentiment_conformity_score'] = 0.0  # çˆ¶è¯„è®ºçš„åŸå§‹åˆ†æ•°ä¸º0
        df['normalized_sentiment_conformity_score'] = 0.0  # çˆ¶è¯„è®ºçš„å½’ä¸€åŒ–åˆ†æ•°ä¸º0
        df['sentiment_type'] = 'neutral'  # é»˜è®¤æƒ…æ„Ÿç±»å‹
        df['sentiment_score'] = 0.0  # é»˜è®¤æƒ…æ„Ÿåˆ†æ•°
        df['sentiment_confidence'] = 0.0  # é»˜è®¤ç½®ä¿¡åº¦
        
        # æ›´æ–°çˆ¶è¯„è®ºçš„æƒ…æ„Ÿä¿¡æ¯
        parent_idx = parent_data.index[0]
        df.loc[parent_idx, 'sentiment_type'] = parent_sentiment_type
        df.loc[parent_idx, 'sentiment_score'] = parent_score
        df.loc[parent_idx, 'sentiment_confidence'] = parent_sentiment['confidence']
        df.loc[parent_idx, 'normalized_sentiment_conformity_score'] = parent_conformity_score
        
        # æ›´æ–°å­è¯„è®ºçš„åˆ†æ•°
        child_indices = child_data.index
        for i, idx in enumerate(child_indices):
            child_sentiment = sentiment_results[i + 1]
            df.loc[idx, 'sentiment_difference'] = sentiment_differences[i]
            df.loc[idx, 'raw_sentiment_conformity_score'] = sentiment_differences[i]
            df.loc[idx, 'normalized_sentiment_conformity_score'] = conformity_scores[i]
            df.loc[idx, 'sentiment_type'] = child_sentiment['sentiment']
            df.loc[idx, 'sentiment_score'] = child_sentiment['score']
            df.loc[idx, 'sentiment_confidence'] = child_sentiment['confidence']
        
        # æ·»åŠ æƒ…æ„Ÿåˆ†ç±»
        df['sentiment_category'] = self._categorize_sentiment_differences(df['sentiment_difference'].tolist())
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        with self._stats_lock:
            self.stats['total_analyzed'] += len(df)
            self.stats['parent_comments'] += 1
            self.stats['child_comments'] += len(child_data)
        
        logger.info(f"æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°è®¡ç®—å®Œæˆï¼Œå…±å¤„ç† {len(df)} æ¡è¯„è®º")
        logger.info(f"çˆ¶è¯„è®ºæƒ…æ„Ÿ: {parent_sentiment_type}, å­è¯„è®ºæ•°é‡: {len(child_data)}")
        
        if return_dict:
            return df.to_dict('records')
        else:
            return df
    
    def _categorize_sentiment_differences(self, sentiment_differences: List[float]) -> List[str]:
        """
        å¯¹æƒ…æ„Ÿå·®å¼‚è¿›è¡Œåˆ†ç±»
        
        Args:
            sentiment_differences: æƒ…æ„Ÿå·®å¼‚åˆ—è¡¨
            
        Returns:
            List[str]: æƒ…æ„Ÿåˆ†ç±»åˆ—è¡¨
        """
        categories = []
        for diff in sentiment_differences:
            if diff == 0:  # çˆ¶è¯„è®º
                categories.append('çˆ¶è¯„è®º')
            elif diff <= 0.1:  # å·®å¼‚å¾ˆå°
                categories.append('é«˜åº¦æƒ…æ„Ÿä»ä¼—')
            elif diff <= 0.3:  # å·®å¼‚è¾ƒå°
                categories.append('ä¸­åº¦æƒ…æ„Ÿä»ä¼—')
            elif diff <= 0.5:  # å·®å¼‚ä¸­ç­‰
                categories.append('è½»åº¦æƒ…æ„Ÿä»ä¼—')
            elif diff <= 0.8:  # å·®å¼‚è¾ƒå¤§
                categories.append('ä½åº¦æƒ…æ„Ÿä»ä¼—')
            else:  # å·®å¼‚å¾ˆå¤§
                categories.append('éæƒ…æ„Ÿä»ä¼—')
        
        return categories
    
    def calculate_parent_sentiment_conformity_score(self, data: Union[pd.DataFrame, List[Dict]]) -> Dict:
        """
        è®¡ç®—çˆ¶è¯„è®ºçš„æ€»ä½“æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°
        
        Args:
            data: åŒ…å«è¯„è®ºæ•°æ®çš„DataFrameæˆ–å­—å…¸åˆ—è¡¨
            
        Returns:
            Dict: çˆ¶è¯„è®ºæƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°ç»Ÿè®¡ç»“æœ
        """
        logger.info("å¼€å§‹è®¡ç®—çˆ¶è¯„è®ºæƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°...")
        
        # è®¡ç®—æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°
        result_data = self.calculate_sentiment_conformity_score(data)
        
        # è½¬æ¢ä¸ºDataFrameæ ¼å¼è¿›è¡Œå¤„ç†
        if isinstance(result_data, list):
            df = pd.DataFrame(result_data)
        else:
            df = result_data
        
        # åˆ†ç¦»çˆ¶è¯„è®ºå’Œå­è¯„è®º
        parent_data = df[df['is_parent'] == True]
        child_data = df[df['is_parent'] == False]
        
        if len(parent_data) == 0:
            raise ValueError("æœªæ‰¾åˆ°çˆ¶è¯„è®ºæ•°æ®")
        
        parent_comment = parent_data.iloc[0]
        parent_id = parent_comment['comment_id']
        parent_sentiment_score = parent_comment['sentiment_score']
        parent_sentiment_type = parent_comment['sentiment_type']
        
        # è®¡ç®—å­è¯„è®ºçš„æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°ç»Ÿè®¡
        child_scores = child_data['normalized_sentiment_conformity_score'].tolist()
        child_sentiment_diffs = child_data['sentiment_difference'].tolist()
        
        if len(child_scores) == 0:
            logger.warning("æœªæ‰¾åˆ°å­è¯„è®ºæ•°æ®")
            return {
                'parent_comment_id': parent_id,
                'parent_sentiment_score': parent_sentiment_score,
                'child_comment_count': 0,
                'parent_sentiment_conformity_score': 0.0,
                'message': 'æ— å­è¯„è®ºæ•°æ®'
            }
        
        # åŸºç¡€ç»Ÿè®¡
        avg_score = np.mean(child_scores)
        median_score = np.median(child_scores)
        max_score = np.max(child_scores)
        min_score = np.min(child_scores)
        std_score = np.std(child_scores)
        
        # é«˜ä»ä¼—å¿ƒç†æ¯”ä¾‹ï¼ˆåˆ†æ•° > 0.7ï¼‰
        high_conformity_count = sum(1 for score in child_scores if score > 0.7)
        high_conformity_ratio = high_conformity_count / len(child_scores)
        
        # æƒ…æ„Ÿå·®å¼‚ç»Ÿè®¡
        avg_sentiment_diff = np.mean(child_sentiment_diffs)
        median_sentiment_diff = np.median(child_sentiment_diffs)
        min_sentiment_diff = np.min(child_sentiment_diffs)
        max_sentiment_diff = np.max(child_sentiment_diffs)
        
        # æƒ…æ„Ÿåˆ†ç±»ç»Ÿè®¡
        sentiment_categories = child_data['sentiment_category'].value_counts()
        
        result = {
            'parent_comment_id': parent_id,
            'parent_sentiment_score': parent_sentiment_score,
            'parent_sentiment_type': parent_sentiment_type,
            'child_comment_count': len(child_scores),
            'parent_sentiment_conformity_score': avg_score,  # ä¸»è¦åˆ†æ•°ï¼šå¹³å‡å€¼
            'statistics': {
                'mean_score': avg_score,
                'median_score': median_score,
                'max_score': max_score,
                'min_score': min_score,
                'std_score': std_score
            },
            'conformity_distribution': {
                'high_conformity_count': high_conformity_count,
                'high_conformity_ratio': high_conformity_ratio,
                'sentiment_category_distribution': sentiment_categories.to_dict()
            },
            'sentiment_analysis': {
                'avg_sentiment_difference': avg_sentiment_diff,
                'median_sentiment_difference': median_sentiment_diff,
                'min_sentiment_difference': min_sentiment_diff,
                'max_sentiment_difference': max_sentiment_diff
            },
            'parent_info': {
                'sentiment_score': parent_sentiment_score,
                'sentiment_type': parent_sentiment_type,
                'comment_id': parent_id
            }
        }
        
        logger.info(f"çˆ¶è¯„è®ºæƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°è®¡ç®—å®Œæˆ: {parent_id}, åˆ†æ•°: {avg_score:.4f}")
        
        return result
    
    def analyze_sentiment_conformity_patterns(self, data: pd.DataFrame) -> Dict[str, any]:
        """
        åˆ†ææƒ…æ„Ÿä»ä¼—å¿ƒç†æ¨¡å¼
        
        Args:
            data: åŒ…å«æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°çš„DataFrame
            
        Returns:
            Dict: æƒ…æ„Ÿä»ä¼—å¿ƒç†æ¨¡å¼åˆ†æç»“æœ
        """
        logger.info("å¼€å§‹åˆ†ææƒ…æ„Ÿä»ä¼—å¿ƒç†æ¨¡å¼...")
        
        analysis_results = {}
        
        # 1. æ•´ä½“ç»Ÿè®¡
        analysis_results['overall_stats'] = {
            'total_comments': len(data),
            'parent_comments': len(data[data['is_parent'] == True]),
            'child_comments': len(data[data['is_parent'] == False]),
            'avg_sentiment_conformity_score': float(data['normalized_sentiment_conformity_score'].mean()),
            'median_sentiment_conformity_score': float(data['normalized_sentiment_conformity_score'].median()),
            'std_sentiment_conformity_score': float(data['normalized_sentiment_conformity_score'].std())
        }
        
        # 2. æƒ…æ„Ÿä»ä¼—å¿ƒç†ç›¸å…³æ€§åˆ†æ
        if len(data) > 1:
            sentiment_scores = data['sentiment_score'].values
            conformity_scores = data['normalized_sentiment_conformity_score'].values
            correlation = np.corrcoef(sentiment_scores, conformity_scores)[0, 1]
            analysis_results['sentiment_conformity_correlation'] = float(correlation)
        else:
            analysis_results['sentiment_conformity_correlation'] = 0.0
        
        # 3. é«˜ä»ä¼—å¿ƒç†åˆ†æ
        high_conformity_threshold = 0.7
        high_conformity_data = data[data['normalized_sentiment_conformity_score'] >= high_conformity_threshold]
        analysis_results['high_conformity_analysis'] = {
            'count': len(high_conformity_data),
            'percentage': len(high_conformity_data) / len(data) * 100 if len(data) > 0 else 0,
            'avg_sentiment_score': float(high_conformity_data['sentiment_score'].mean()) if len(high_conformity_data) > 0 else 0.0
        }
        
        # 4. æƒ…æ„Ÿç±»å‹åˆ†å¸ƒ
        sentiment_type_dist = data['sentiment_type'].value_counts()
        analysis_results['sentiment_type_distribution'] = sentiment_type_dist.to_dict()
        
        # 5. æƒ…æ„Ÿåˆ†ç±»åˆ†å¸ƒ
        sentiment_category_dist = data['sentiment_category'].value_counts()
        analysis_results['sentiment_category_distribution'] = sentiment_category_dist.to_dict()
        
        logger.info("æƒ…æ„Ÿä»ä¼—å¿ƒç†æ¨¡å¼åˆ†æå®Œæˆ")
        
        return analysis_results
    
    def generate_sentiment_conformity_report(self, data: pd.DataFrame, 
                                           analysis_results: Dict[str, any]) -> str:
        """
        ç”Ÿæˆæƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†ææŠ¥å‘Š
        
        Args:
            data: åŒ…å«åˆ†æç»“æœçš„DataFrame
            analysis_results: åˆ†æç»“æœå­—å…¸
            
        Returns:
            str: Markdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š
        """
        logger.info("ç”Ÿæˆæƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†ææŠ¥å‘Š...")
        
        # è·å–çˆ¶è¯„è®ºä¿¡æ¯
        parent_data = data[data['is_parent'] == True]
        if len(parent_data) > 0:
            parent_comment = parent_data.iloc[0]
            parent_id = parent_comment['comment_id']
            parent_content = parent_comment['content']
            parent_sentiment = parent_comment['sentiment_type']
            parent_score = parent_comment['sentiment_score']
        else:
            parent_id = "æœªçŸ¥"
            parent_content = "æœªçŸ¥"
            parent_sentiment = "æœªçŸ¥"
            parent_score = 0.0
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""# æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†ææŠ¥å‘Š

## ğŸ“Š åˆ†ææ¦‚è§ˆ

- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **çˆ¶è¯„è®ºID**: {parent_id}
- **çˆ¶è¯„è®ºå†…å®¹**: {parent_content}
- **çˆ¶è¯„è®ºæƒ…æ„Ÿ**: {parent_sentiment} (åˆ†æ•°: {parent_score:.4f})
- **æ€»è¯„è®ºæ•°**: {analysis_results['overall_stats']['total_comments']}
- **å­è¯„è®ºæ•°**: {analysis_results['overall_stats']['child_comments']}

## ğŸ¯ æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æç»“æœ

### æ•´ä½“ç»Ÿè®¡
- **å¹³å‡æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°**: {analysis_results['overall_stats']['avg_sentiment_conformity_score']:.4f}
- **ä¸­ä½æ•°æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°**: {analysis_results['overall_stats']['median_sentiment_conformity_score']:.4f}
- **æ ‡å‡†å·®**: {analysis_results['overall_stats']['std_sentiment_conformity_score']:.4f}

### é«˜ä»ä¼—å¿ƒç†åˆ†æ
- **é«˜ä»ä¼—è¯„è®ºæ•°é‡**: {analysis_results['high_conformity_analysis']['count']}
- **é«˜ä»ä¼—æ¯”ä¾‹**: {analysis_results['high_conformity_analysis']['percentage']:.1f}%
- **é«˜ä»ä¼—è¯„è®ºå¹³å‡æƒ…æ„Ÿåˆ†æ•°**: {analysis_results['high_conformity_analysis']['avg_sentiment_score']:.4f}

### æƒ…æ„Ÿç›¸å…³æ€§
- **æƒ…æ„Ÿåˆ†æ•°ä¸ä»ä¼—å¿ƒç†ç›¸å…³æ€§**: {analysis_results['sentiment_conformity_correlation']:.4f}

## ğŸ“ˆ æƒ…æ„Ÿç±»å‹åˆ†å¸ƒ

"""
        
        # æ·»åŠ æƒ…æ„Ÿç±»å‹åˆ†å¸ƒ
        for sentiment_type, count in analysis_results['sentiment_type_distribution'].items():
            percentage = count / analysis_results['overall_stats']['total_comments'] * 100
            report += f"- **{sentiment_type}**: {count} æ¡ ({percentage:.1f}%)\n"
        
        report += "\n## ğŸ·ï¸ æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†ç±»åˆ†å¸ƒ\n\n"
        
        # æ·»åŠ æƒ…æ„Ÿåˆ†ç±»åˆ†å¸ƒ
        for category, count in analysis_results['sentiment_category_distribution'].items():
            percentage = count / analysis_results['overall_stats']['total_comments'] * 100
            report += f"- **{category}**: {count} æ¡ ({percentage:.1f}%)\n"
        
        # æ·»åŠ å‰5åé«˜ä»ä¼—å¿ƒç†è¯„è®º
        high_conformity_comments = data[data['is_parent'] == False].nlargest(5, 'normalized_sentiment_conformity_score')
        if len(high_conformity_comments) > 0:
            report += "\n## â­ å‰5åé«˜æƒ…æ„Ÿä»ä¼—å¿ƒç†è¯„è®º\n\n"
            for i, (_, row) in enumerate(high_conformity_comments.iterrows(), 1):
                report += f"{i}. **è¯„è®ºID**: {row['comment_id']}\n"
                report += f"   - **å†…å®¹**: {row['content']}\n"
                report += f"   - **æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°**: {row['normalized_sentiment_conformity_score']:.4f}\n"
                report += f"   - **æƒ…æ„Ÿç±»å‹**: {row['sentiment_type']}\n"
                report += f"   - **æƒ…æ„Ÿåˆ†æ•°**: {row['sentiment_score']:.4f}\n"
                report += f"   - **æƒ…æ„Ÿå·®å¼‚**: {row['sentiment_difference']:.4f}\n\n"
        
        report += f"\n---\n\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        
        return report
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        if stats['api_calls'] > 0:
            stats['avg_confidence'] = stats['total_confidence'] / stats['api_calls']
            stats['avg_sentiment_score'] = stats['total_sentiment_score'] / stats['api_calls']
        else:
            stats['avg_confidence'] = 0.0
            stats['avg_sentiment_score'] = 0.0
        return stats
    
    def analyze(self, data: Union[pd.DataFrame, List[Dict]]) -> Dict:
        """
        å®ç°BaseAnalyzerçš„analyzeæ–¹æ³•
        """
        logger.info("å¼€å§‹æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ...")
        
        # è®¡ç®—æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°
        processed_data = self.calculate_sentiment_conformity_score(data)
        if isinstance(processed_data, list):
            processed_df = pd.DataFrame(processed_data)
        else:
            processed_df = processed_data
        
        # è®¡ç®—çˆ¶è¯„è®ºæ€»ä½“æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°
        parent_overall_result = self.calculate_parent_sentiment_conformity_score(processed_df)
        
        # åˆ†ææƒ…æ„Ÿä»ä¼—å¿ƒç†æ¨¡å¼
        pattern_results = self.analyze_sentiment_conformity_patterns(processed_df)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = self.generate_sentiment_conformity_report(processed_df, pattern_results)
        
        # å‡†å¤‡è¾“å‡ºç»“æœ
        output_result = {
            "analysis_metadata": {
                "analysis_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "analyzer_version": "v1.0.0",
                "data_source": getattr(self, 'data_source', 'unknown'),
                "total_comments": len(processed_df)
            },
            "parent_comment_info": {
                "comment_id": parent_overall_result.get('parent_comment_id', 'N/A'),
                "content": processed_df[processed_df['comment_id'] == parent_overall_result.get('parent_comment_id', 'N/A')]['content'].iloc[0] if not processed_df[processed_df['comment_id'] == parent_overall_result.get('parent_comment_id', 'N/A')].empty else 'N/A',
            },
            "parent_environment_sentiment_analysis": parent_overall_result,
            "sentiment_classification": pattern_results.get('sentiment_category_distribution', {}),
            "top_high_sentiment_comments": processed_df.nlargest(10, 'normalized_sentiment_conformity_score').to_dict('records') if not processed_df.empty else []
        }
        
        logger.info("æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æå®Œæˆ")
        return output_result

def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser("sentiment_conformity_analyzer", "æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ")
    parser.add_argument('--sa-concurrency', type=int, default=8, help='æƒ…æ„ŸAPIå¹¶å‘æ•°ï¼Œé»˜è®¤8')
    parser.add_argument('--sa-batch-size', type=int, default=200, help='æƒ…æ„ŸAPIæ‰¹å¤§å°ï¼Œé»˜è®¤200')
    parser.add_argument('--sa-throttle-ms', type=int, default=0, help='æƒ…æ„ŸAPIèŠ‚æµæ¯«ç§’ï¼Œé»˜è®¤0=ä¸é™åˆ¶')
    
    args = parser.parse_args()
    args = parse_common_args(parser, args)
    
    # æ£€æŸ¥é˜¿é‡Œäº‘APIé…ç½®
    if not is_aliyun_api_available():
        logger.error("é˜¿é‡Œäº‘APIé…ç½®ç¼ºå¤±ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡")
        return
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = SentimentConformityAnalyzer(
        module_name="sentiment_conformity_analyzer",
        video_id=args.video_id,
        sa_concurrency=args.sa_concurrency,
        sa_batch_size=args.sa_batch_size,
        sa_throttle_ms=args.sa_throttle_ms
    )
    
    # åŠ è½½æ•°æ®
    if args.use_cleaned_data:
        logger.info(f"ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®: {args.cleaned_data_path}")
        data = analyzer.load_data(use_cleaned_data=True, cleaned_data_path=args.cleaned_data_path)
    else:
        logger.info("ä»æ•°æ®åº“åŠ è½½æ•°æ®...")
        data = analyzer.load_data(limit=args.limit)
    
    if data is None or len(data) == 0:
        logger.error("æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
        return
    
    # è¿è¡Œåˆ†æ
    try:
        # è®¡ç®—æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°
        result_data = analyzer.calculate_sentiment_conformity_score(data)
        
        # è®¡ç®—çˆ¶è¯„è®ºæƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ•°
        parent_result = analyzer.calculate_parent_sentiment_conformity_score(data)
        
        # åˆ†ææ¨¡å¼
        analysis_results = analyzer.analyze_sentiment_conformity_patterns(result_data)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = analyzer.generate_sentiment_conformity_report(result_data, analysis_results)
        
        # ä¿å­˜ç»“æœ
        analyzer.save_results(result_data, parent_result, analysis_results, report)
        
        logger.info("æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æå®Œæˆ")
        
    except Exception as e:
        logger.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
