#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æœ¬åˆ†ææ¨¡å—åŸºç±»
æä¾›ç»Ÿä¸€çš„åˆ†ææ¥å£å’Œé€šç”¨åŠŸèƒ½
"""

import os
import sys
import json
import argparse
import logging
from datetime import datetime
from typing import Dict, List, Union, Optional
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

import pandas as pd
import matplotlib.pyplot as plt
from text_analysis.core.db_config import get_db_conn
from text_analysis.core.data_paths import AnalysisPathManager, PROJECT_ROOT, resolve_latest_cleaned_data

# ä½¿ç”¨PROJECT_ROOTä½œä¸ºé¡¹ç›®æ ¹ç›®å½•
project_root = PROJECT_ROOT

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BaseAnalyzer:
    """åˆ†ææ¨¡å—åŸºç±»"""
    
    def __init__(self, module_name: str, video_id: str = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            module_name: æ¨¡å—åç§°
            video_id: è§†é¢‘ID
        """
        self.module_name = module_name
        self.video_id = video_id
        self.path_manager = AnalysisPathManager(module_name, video_id)
        self.conn = None
        
    def connect_database(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = get_db_conn()
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def close_database(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            print("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def load_data(self, limit: Optional[int] = None, use_cleaned_data: bool = False, cleaned_data_path: str = None) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®
        
        Args:
            limit: é™åˆ¶æ•°æ®é‡
            use_cleaned_data: æ˜¯å¦ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®
            cleaned_data_path: æ¸…æ´—æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            DataFrame: åŠ è½½çš„æ•°æ®
        """
        if use_cleaned_data:
            return self._load_from_cleaned_data(cleaned_data_path)
        else:
            return self._load_from_database(limit)
    
    def _load_from_database(self, limit: Optional[int] = None) -> pd.DataFrame:
        """ä»æ•°æ®åº“åŠ è½½æ•°æ®"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")
    
    def _load_from_cleaned_data(self, cleaned_data_path: str = None) -> pd.DataFrame:
        """ä»æ¸…æ´—æ•°æ®æ–‡ä»¶åŠ è½½æ•°æ®"""
        try:
            if cleaned_data_path is None:
                # ä¼˜å…ˆè§£ææœ€æ–°çš„æ¸…æ´—æ•°æ®ï¼ˆå…¼å®¹æ–°è€å‘½åï¼‰
                auto_path = resolve_latest_cleaned_data(self.video_id)
                cleaned_data_path = auto_path or os.path.join(PROJECT_ROOT, 'data', 'processed', 'douyin_comments_processed.json')
            
            if not os.path.exists(cleaned_data_path):
                print(f"âŒ æ¸…æ´—æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {cleaned_data_path}")
                return pd.DataFrame()
            
            with open(cleaned_data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            df = pd.DataFrame(data)
            # å¦‚æŒ‡å®š video_idï¼Œåˆ™æŒ‰ aweme_id è¿‡æ»¤
            if self.video_id and 'aweme_id' in df.columns:
                df = df[df['aweme_id'] == self.video_id]
            print(f"âœ… æˆåŠŸåŠ è½½æ¸…æ´—æ•°æ®: {len(df)} æ¡è®°å½•")
            return df
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ¸…æ´—æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def analyze(self, df: pd.DataFrame) -> Dict:
        """
        æ‰§è¡Œåˆ†æ
        
        Args:
            df: è¾“å…¥æ•°æ®
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")
    
    def save_results(self, df: pd.DataFrame, results: Dict):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            # ä¿å­˜CSVç»“æœ
            csv_path = self.path_manager.get_results_paths()['csv']
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
            
            # ä¿å­˜JSONç»“æœ
            json_path = self.path_manager.get_results_paths()['json']
            results_data = {
                'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'module_name': self.module_name,
                'video_id': self.video_id,
                'total_records': len(df),
                'results': results
            }
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, ensure_ascii=False, indent=2)
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {json_path}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def generate_report(self, df: pd.DataFrame, results: Dict):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        try:
            report_path = self.path_manager.get_report_path()
            
            report = {
                'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'module_name': self.module_name,
                'video_id': self.video_id,
                'summary': {
                    'total_records': len(df),
                    'analysis_duration': results.get('duration', 0)
                },
                'detailed_results': results
            }
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
            
            # æ‰“å°æŠ¥å‘Šæ‘˜è¦
            self._print_report_summary(report)
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def create_visualizations(self, df: pd.DataFrame, results: Dict):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        try:
            viz_path = self.path_manager.get_visualization_path()
            self._create_charts(df, results, viz_path)
            print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {viz_path}")
        except Exception as e:
            print(f"âŒ åˆ›å»ºå¯è§†åŒ–å¤±è´¥: {e}")
    
    def _create_charts(self, df: pd.DataFrame, results: Dict, output_path: str):
        """åˆ›å»ºå›¾è¡¨ï¼ˆå­ç±»å¯é‡å†™ï¼‰"""
        # é»˜è®¤å®ç°ï¼šåˆ›å»ºç®€å•çš„ç»Ÿè®¡å›¾è¡¨
        fig, axes = plt.subplots(1, 1, figsize=(10, 6))
        fig.suptitle(f'{self.module_name.title()} åˆ†æç»“æœ', fontsize=16, fontweight='bold')
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ é»˜è®¤çš„å›¾è¡¨å†…å®¹
        axes.text(0.5, 0.5, f'åˆ†æå®Œæˆ\næ€»è®°å½•æ•°: {len(df)}', 
                 ha='center', va='center', transform=axes.transAxes, fontsize=14)
        axes.set_xlim(0, 1)
        axes.set_ylim(0, 1)
        axes.axis('off')
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _print_report_summary(self, report: Dict):
        """æ‰“å°æŠ¥å‘Šæ‘˜è¦"""
        print("\n=== åˆ†ææŠ¥å‘Šæ‘˜è¦ ===")
        print(f"åˆ†ææ—¶é—´: {report['analysis_time']}")
        print(f"æ¨¡å—åç§°: {report['module_name']}")
        if report['video_id']:
            print(f"è§†é¢‘ID: {report['video_id']}")
        print(f"æ€»è®°å½•æ•°: {report['summary']['total_records']:,}")
    
    def run_analysis(self, limit: Optional[int] = None, use_cleaned_data: bool = False, 
                    cleaned_data_path: str = None, save_results: bool = True, 
                    generate_report: bool = True, create_visualizations: bool = True, 
                    strict_mode: bool = False):
        """
        è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹
        
        Args:
            limit: é™åˆ¶æ•°æ®é‡
            use_cleaned_data: æ˜¯å¦ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®
            cleaned_data_path: æ¸…æ´—æ•°æ®æ–‡ä»¶è·¯å¾„
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            generate_report: æ˜¯å¦ç”ŸæˆæŠ¥å‘Š
            create_visualizations: æ˜¯å¦åˆ›å»ºå¯è§†åŒ–
            strict_mode: æ˜¯å¦ä½¿ç”¨ä¸¥æ ¼æ¨¡å¼ï¼ˆä¸»è¦ç”¨äºæ•°æ®æ¸…æ´—æ¨¡å—ï¼‰
        """
        print(f"=== {self.module_name.title()} åˆ†æå¼€å§‹ ===")
        
        # è¿æ¥æ•°æ®åº“
        if not use_cleaned_data and not self.connect_database():
            return
        
        try:
            # åŠ è½½æ•°æ®
            df = self.load_data(limit, use_cleaned_data, cleaned_data_path)
            if df.empty:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
                return
            
            # æ‰§è¡Œåˆ†æ
            start_time = datetime.now()
            # ä¼ é€’strict_modeå‚æ•°ç»™analyzeæ–¹æ³•
            results = self.analyze(df, strict_mode=strict_mode)
            end_time = datetime.now()
            results['duration'] = (end_time - start_time).total_seconds()
            
            # æ¸…æ´—æ¨¡å—é¢å¤–æ‰“å°æ‘˜è¦
            if self.module_name == 'cleaning':
                try:
                    orig = results.get('original_stats', {})
                    fin = results.get('final_stats', {})
                    # ç¾åŒ–ç»ˆç«¯æ‘˜è¦è¾“å‡º
                    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¸…æ´—æ‘˜è¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
                    print(f"â”‚ åŸå§‹æ€»è¯„è®º: {orig.get('total_comments', 0):,}    çˆ¶:{orig.get('parent_comments','?')}  å­:{orig.get('child_comments','?')}")
                    print(f"â”‚ æ¸…æ´—åæ€»è¯„è®º: {fin.get('total_comments', 0):,}  çˆ¶:{fin.get('parent_comments','?')}  å­:{fin.get('child_comments','?')}")
                    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
                except Exception:
                    pass

            # ä¿å­˜ç»“æœ
            if save_results:
                self.save_results(df, results)
            
            # ç”ŸæˆæŠ¥å‘Š
            if generate_report:
                self.generate_report(df, results)
            
            # åˆ›å»ºå¯è§†åŒ–
            if create_visualizations:
                self.create_visualizations(df, results)
            
            print(f"\nâœ… {self.module_name.title()} åˆ†æå®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            # å…³é—­æ•°æ®åº“è¿æ¥
            if not use_cleaned_data:
                self.close_database()

def create_parser(module_name: str, description: str) -> argparse.ArgumentParser:
    """åˆ›å»ºç»Ÿä¸€çš„å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument('--video-id', type=str, help='è§†é¢‘IDï¼Œå¦‚æœä¸æŒ‡å®šåˆ™åˆ†ææ‰€æœ‰æ•°æ®')
    parser.add_argument('--limit', type=int, help='é™åˆ¶åˆ†ææ•°é‡')
    parser.add_argument('--use-cleaned-data', action='store_true', help='ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®æ–‡ä»¶')
    parser.add_argument('--cleaned-data-path', type=str, help='æ¸…æ´—æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼Œåªåˆ†æå°‘é‡æ•°æ®')
    parser.add_argument('--no-save', action='store_true', help='ä¸ä¿å­˜ç»“æœæ–‡ä»¶')
    parser.add_argument('--no-report', action='store_true', help='ä¸ç”Ÿæˆåˆ†ææŠ¥å‘Š')
    parser.add_argument('--no-viz', action='store_true', help='ä¸åˆ›å»ºå¯è§†åŒ–å›¾è¡¨')
    
    return parser

def parse_common_args(parser: argparse.ArgumentParser, args):
    """è§£æé€šç”¨å‚æ•°"""
    # æµ‹è¯•æ¨¡å¼è®¾ç½®
    if args.test:
        if not args.limit:
            args.limit = 10
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªåˆ†æå°‘é‡æ•°æ®")
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print(f"=== {parser.description} ===")
    if args.video_id:
        print(f"è§†é¢‘ID: {args.video_id}")
    if args.limit:
        print(f"é™åˆ¶æ•°é‡: {args.limit}")
    if args.use_cleaned_data:
        print("ä½¿ç”¨æ¸…æ´—æ•°æ®")
    print("=" * 30)
    
    return args
