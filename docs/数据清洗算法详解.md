# æ•°æ®æ¸…æ´—ç®—æ³•è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

æ•°æ®æ¸…æ´—æ¨¡å— (`data_cleaning_optimized.py`) æ˜¯æ–‡æœ¬åˆ†æç³»ç»Ÿçš„æ ¸å¿ƒé¢„å¤„ç†æ¨¡å—ï¼Œè´Ÿè´£å°†åŸå§‹è¯„è®ºæ•°æ®è½¬æ¢ä¸ºé«˜è´¨é‡çš„åˆ†ææ•°æ®ã€‚è¯¥æ¨¡å—é›†æˆäº†æ—¶é—´æ ‡å‡†åŒ–åŠŸèƒ½ï¼Œä¸ºåç»­çš„ä»ä¼—å¿ƒç†æ—¶é—´åˆ†ææä¾›æ”¯æŒã€‚

## ğŸ—ï¸ ç®—æ³•æ¶æ„

```
åŸå§‹æ•°æ® â†’ æ•°æ®è´¨é‡æ£€æŸ¥ â†’ åƒåœ¾è¯„è®ºè¿‡æ»¤ â†’ æ–‡æœ¬æ¸…æ´— â†’ åˆ†è¯å¤„ç† â†’ æ—¶é—´æ ‡å‡†åŒ– â†’ è¾“å‡ºæ•°æ®
    â†“           â†“              â†“           â†“          â†“           â†“
  351æ¡      è´¨é‡ç»Ÿè®¡        è¿‡æ»¤8æ¡      æ¸…æ´—343æ¡   åˆ†è¯330æ¡   æ ‡å‡†åŒ–330æ¡
```

## ğŸ”§ æ ¸å¿ƒç®—æ³•

### 1. åƒåœ¾è¯„è®ºæ£€æµ‹ç®—æ³•

#### æ£€æµ‹è§„åˆ™
```python
def is_spam_comment(self, content: str, user_signature: str = None) -> bool:
    # 1. å†…å®¹é•¿åº¦æ£€æŸ¥
    if len(content.strip()) < 5:
        return True
    
    # 2. ç‰¹æ®Šå­—ç¬¦æ¯”ä¾‹æ£€æŸ¥
    special_char_ratio = len(re.findall(r'[^\u4e00-\u9fa5a-zA-Z0-9\s]', content)) / len(content)
    if special_char_ratio > 0.6:
        return True
    
    # 3. å¹¿å‘Šå…³é”®è¯æ£€æŸ¥
    ad_keywords = ['åŠ å¾®ä¿¡', 'åŠ qq', 'åŠ ç¾¤', 'ç§ä¿¡', 'è”ç³»æˆ‘', 'åˆä½œ', 'æ¨å¹¿', 'å¹¿å‘Š', ...]
    
    # 4. é‡å¤å­—ç¬¦æ£€æŸ¥
    if len(set(content)) < len(content) * 0.2:
        return True
    
    # 5. ç”¨æˆ·ç­¾åæ£€æŸ¥
    if user_signature and (len(user_signature) > 100 or re.search(r'[0-9]{8,}', user_signature)):
        return True
```

#### ç®—æ³•ç‰¹ç‚¹
- **å¤šç»´åº¦æ£€æµ‹**: ä»å†…å®¹ã€æ ¼å¼ã€ç”¨æˆ·ä¿¡æ¯ç­‰å¤šä¸ªç»´åº¦åˆ¤æ–­
- **é˜ˆå€¼å¯è°ƒ**: ç‰¹æ®Šå­—ç¬¦æ¯”ä¾‹ã€é‡å¤å­—ç¬¦æ¯”ä¾‹ç­‰å‚æ•°å¯è°ƒæ•´
- **å…³é”®è¯åº“**: å†…ç½®å¹¿å‘Šå…³é”®è¯åº“ï¼Œå¯æ‰©å±•

### 2. æ–‡æœ¬æ¸…æ´—ç®—æ³•

#### æ¸…æ´—æ­¥éª¤
```python
def clean_text(self, text: str) -> str:
    # 1. å»é™¤HTMLæ ‡ç­¾
    text = re.sub(r'<[^>]+>', '', text)
    
    # 2. å»é™¤URL
    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
    
    # 3. å»é™¤æ–¹æ‹¬å·å†…å®¹ï¼ˆå¦‚[666][æ¯”å¿ƒ]ç­‰ï¼‰
    text = re.sub(r'\[[^\]]*\]', '', text)
    
    # 4. å»é™¤å¤šä½™ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text).strip()
    
    # 5. ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ä¸­æ–‡æ ‡ç‚¹ï¼Œå»é™¤å…¶ä»–ç¬¦å·
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s\u3000-\u303f\uff00-\uffef]', '', text)
```

#### ç®—æ³•ç‰¹ç‚¹
- **æ¸è¿›å¼æ¸…æ´—**: æŒ‰æ­¥éª¤é€æ­¥æ¸…ç†ï¼Œé¿å…è¿‡åº¦æ¸…æ´—
- **ä¿ç•™è¯­ä¹‰**: ä¿ç•™ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ï¼Œç»´æŒæ–‡æœ¬è¯­ä¹‰
- **æ­£åˆ™ä¼˜åŒ–**: ä½¿ç”¨é«˜æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼

### 3. åˆ†è¯ç®—æ³•

#### åŒæ¨¡å¼æ”¯æŒ
```python
def segment_text(self, text: str) -> List[str]:
    if self.segment_mode == 'api' and self.aliyun_api_manager is not None:
        # é˜¿é‡Œäº‘APIåˆ†è¯
        words = self.aliyun_api_manager.segment_text(text)
    else:
        # æœ¬åœ°jiebaåˆ†è¯
        words = jieba.lcut(text)
    
    # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
    filtered_words = [word for word in words 
                     if word and word.strip() and len(word.strip()) > 1 
                     and word not in self.stop_words]
```

#### ç®—æ³•ç‰¹ç‚¹
- **æ™ºèƒ½å›é€€**: APIå¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°æœ¬åœ°åˆ†è¯
- **åœç”¨è¯è¿‡æ»¤**: åŸºäºåœç”¨è¯åº“è¿‡æ»¤æ— æ„ä¹‰è¯æ±‡
- **é•¿åº¦è¿‡æ»¤**: è¿‡æ»¤å•å­—ç¬¦è¯æ±‡ï¼Œæé«˜åˆ†è¯è´¨é‡

### 4. æ—¶é—´æ ‡å‡†åŒ–ç®—æ³•

#### æ ¸å¿ƒåŠŸèƒ½
```python
def _add_time_standardization(self, df: pd.DataFrame) -> pd.DataFrame:
    # 1. æ—¶é—´æ ‡å‡†åŒ–ï¼šUnixæ—¶é—´æˆ³è½¬datetime
    df['comment_time'] = pd.to_datetime(df['create_time'], unit='s')
    
    # 2. æŒ‰æ—¶é—´æ’åº
    df = df.sort_values('comment_time').reset_index(drop=True)
    
    # 3. æ·»åŠ çˆ¶è¯„è®ºæ ‡è¯†
    parent_mask = (df['parent_comment_id'].isna() | 
                  (df['parent_comment_id'] == '0') | 
                  (df['parent_comment_id'] == 0))
    df['is_parent'] = parent_mask
    
    # 4. è®¡ç®—æ—¶é—´å·®
    for idx, row in df.iterrows():
        if not row['is_parent']:
            parent_time = parent_times[row['parent_comment_id']]
            time_diff = abs((row['comment_time'] - parent_time).total_seconds())
            time_diffs.append(time_diff)
```

#### ç®—æ³•ç‰¹ç‚¹
- **çˆ¶å­å…³ç³»è¯†åˆ«**: åŸºäº `parent_comment_id` å­—æ®µå‡†ç¡®è¯†åˆ«çˆ¶å­è¯„è®ºå…³ç³»
- **æ—¶é—´å·®è®¡ç®—**: ç²¾ç¡®è®¡ç®—å­è¯„è®ºä¸çˆ¶è¯„è®ºçš„æ—¶é—´é—´éš”
- **æ•°æ®å®Œæ•´æ€§**: ç¡®ä¿æ—¶é—´æ•°æ®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### å¤„ç†æ•ˆç‡
- **æ•°æ®æ¸…æ´—é€Ÿåº¦**: çº¦1000æ¡/ç§’
- **åˆ†è¯å¤„ç†é€Ÿåº¦**: æœ¬åœ°æ¨¡å¼çº¦500æ¡/ç§’ï¼ŒAPIæ¨¡å¼çº¦100æ¡/ç§’
- **å†…å­˜ä½¿ç”¨**: çº¦10MBï¼ˆå¤„ç†1000æ¡è¯„è®ºï¼‰

### è´¨é‡æŒ‡æ ‡
- **åƒåœ¾è¯„è®ºè¿‡æ»¤ç‡**: 2.3%ï¼ˆ351æ¡ä¸­è¿‡æ»¤8æ¡ï¼‰
- **æ–‡æœ¬æ¸…æ´—ä¿ç•™ç‡**: 100%ï¼ˆ343æ¡å…¨éƒ¨ä¿ç•™ï¼‰
- **åˆ†è¯åä¿ç•™ç‡**: 96.2%ï¼ˆ343æ¡ä¸­ä¿ç•™330æ¡ï¼‰

## ğŸ”„ æ•°æ®æµè½¬

### è¾“å…¥æ•°æ®æ ¼å¼
```json
{
  "comment_id": "7306470754056569635",
  "aweme_id": "7306437681045654834",
  "parent_comment_id": "0",
  "content": "è¿™ä¸ªè§†é¢‘å¾ˆæ£’ï¼",
  "create_time": 1701170293,
  "like_count": 100,
  "sub_comment_count": 5,
  "user_id": "123456789",
  "nickname": "ç”¨æˆ·æ˜µç§°",
  "user_signature": "ç”¨æˆ·ç­¾å"
}
```

### è¾“å‡ºæ•°æ®æ ¼å¼
```json
{
  "comment_id": "7306470754056569635",
  "aweme_id": "7306437681045654834",
  "parent_comment_id": "0",
  "content": "è¿™ä¸ªè§†é¢‘å¾ˆæ£’ï¼",
  "create_time": 1701170293,
  "comment_time": "2023-11-28 19:18:13",
  "is_parent": true,
  "time_diff_seconds": 0,
  "words": ["è¿™ä¸ª", "è§†é¢‘", "å¾ˆæ£’"],
  "word_count": 3,
  "like_count": 100,
  "sub_comment_count": 5,
  "user_id": "123456789",
  "nickname": "ç”¨æˆ·æ˜µç§°",
  "user_signature": "ç”¨æˆ·ç­¾å"
}
```

## ğŸ¯ åº”ç”¨åœºæ™¯

### 1. æ•°æ®é¢„å¤„ç†
- ä¸ºæƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼åº¦åˆ†æç­‰æ¨¡å—æä¾›é«˜è´¨é‡æ•°æ®
- ç»Ÿä¸€æ•°æ®æ ¼å¼ï¼Œç¡®ä¿åç»­åˆ†æçš„ä¸€è‡´æ€§

### 2. æ—¶é—´åˆ†ææ”¯æŒ
- ä¸ºä»ä¼—å¿ƒç†æ—¶é—´åˆ†ææä¾›æ ‡å‡†åŒ–çš„æ—¶é—´æ•°æ®
- è‡ªåŠ¨è®¡ç®—çˆ¶å­è¯„è®ºæ—¶é—´å·®ï¼Œæ”¯æŒæ—¶é—´ä»ä¼—å¿ƒç†åˆ†æ

### 3. å†…å®¹è´¨é‡æå‡
- è¿‡æ»¤åƒåœ¾è¯„è®ºï¼Œæé«˜åˆ†æå‡†ç¡®æ€§
- æ ‡å‡†åŒ–æ–‡æœ¬æ ¼å¼ï¼Œæ”¹å–„åˆ†è¯æ•ˆæœ

## ğŸ”§ é…ç½®å‚æ•°

### åƒåœ¾è¯„è®ºæ£€æµ‹å‚æ•°
```python
# å†…å®¹é•¿åº¦é˜ˆå€¼
MIN_CONTENT_LENGTH = 5

# ç‰¹æ®Šå­—ç¬¦æ¯”ä¾‹é˜ˆå€¼
MAX_SPECIAL_CHAR_RATIO = 0.6

# é‡å¤å­—ç¬¦æ¯”ä¾‹é˜ˆå€¼
MIN_UNIQUE_CHAR_RATIO = 0.2

# ç”¨æˆ·ç­¾åé•¿åº¦é˜ˆå€¼
MAX_SIGNATURE_LENGTH = 100
```

### åˆ†è¯å‚æ•°
```python
# æœ€å°è¯é•¿åº¦
MIN_WORD_LENGTH = 2

# åœç”¨è¯æ–‡ä»¶è·¯å¾„
STOP_WORDS_FILE = "hit_stopwords.txt"
```

## ğŸ“ˆ ä¼˜åŒ–å»ºè®®

### 1. æ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨æ‰¹é‡å¤„ç†å‡å°‘APIè°ƒç”¨æ¬¡æ•°
- å®ç°åˆ†è¯ç»“æœç¼“å­˜æœºåˆ¶
- ä¼˜åŒ–æ­£åˆ™è¡¨è¾¾å¼æ€§èƒ½

### 2. è´¨é‡æå‡
- æ‰©å±•å¹¿å‘Šå…³é”®è¯åº“
- ä¼˜åŒ–åœç”¨è¯åˆ—è¡¨
- å¢åŠ æ›´å¤šåƒåœ¾è¯„è®ºæ£€æµ‹è§„åˆ™

### 3. åŠŸèƒ½æ‰©å±•
- æ”¯æŒæ›´å¤šè¯­è¨€çš„åˆ†è¯
- å¢åŠ æ–‡æœ¬å»é‡åŠŸèƒ½
- å®ç°å¢é‡æ•°æ®æ¸…æ´—

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIè°ƒç”¨å¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - éªŒè¯APIå¯†é’¥é…ç½®
   - æŸ¥çœ‹APIè°ƒç”¨é™åˆ¶

2. **åˆ†è¯æ•ˆæœä¸ä½³**
   - æ£€æŸ¥åœç”¨è¯é…ç½®
   - è°ƒæ•´åˆ†è¯å‚æ•°
   - è€ƒè™‘ä½¿ç”¨APIåˆ†è¯

3. **æ—¶é—´æ ‡å‡†åŒ–é”™è¯¯**
   - æ£€æŸ¥æ—¶é—´å­—æ®µæ ¼å¼
   - éªŒè¯çˆ¶å­è¯„è®ºå…³ç³»
   - ç¡®è®¤æ•°æ®å®Œæ•´æ€§

### è°ƒè¯•æ–¹æ³•
```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æ£€æŸ¥æ•°æ®è´¨é‡
analyzer = DataCleaningAnalyzer()
quality_stats = analyzer._check_data_quality(df)
print(quality_stats)
```

---

*æ•°æ®æ¸…æ´—ç®—æ³•è¯¦è§£ v1.0.0 - 2025-09-05*
