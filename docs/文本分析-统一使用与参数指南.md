### 文本分析 - 统一使用与参数指南（合并版）

本指南整合了《模块参数配置指南》和《文本分析使用指南》，提供统一入口的完整使用说明、各模块参数、命名规范、自动索引、常见问题与最佳实践。适用于模块：`cleaning`、`time`、`like`、`sentiment`、`similarity`。

---

### 一、前置准备
- 虚拟环境与依赖
  - Windows（PowerShell）：
    ```powershell
    python -m venv venv
    .\venv\Scripts\Activate.ps1
    pip install -r requirements.txt
    ```
  - macOS/Linux：
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```
- 数据库：配置 `config/db_config.py`
- 阿里云环境变量（用于 sentiment/similarity）：
  ```bash
  NLP_AK_ENV=你的AccessKeyId
  NLP_SK_ENV=你的AccessKeySecret
  NLP_REGION_ENV=cn-hangzhou  # 可选
  ```

---

### 二、统一入口与模块
运行入口：
```bash
python text_analysis/text_analysis_unified.py <module> [options]
```
模块简写：
- cleaning：数据清洗（必跑）
- time：从众心理时间分析
- like：点赞分析
- sentiment：情感分析（默认 aliyun）
- similarity：文本相似度分析

---

### 三、通用参数（全部模块通用）
- `--video-id <str>`：仅分析指定视频；不传则全量
- `--limit <int>`：限制样本条数；`--test` 未设 `--limit` 时默认 10
- `--use-cleaned-data`：使用清洗后的 JSON（除 cleaning 外推荐）
- `--cleaned-data-path <path>`：手动指定清洗文件（一般无需）
- `--test`：测试模式
- `--no-save`：不写入 results
- `--no-report`：不生成报告（sentiment 模块由统一入口忽略）
- `--no-viz`：不生成可视化（sentiment 模块由统一入口忽略）

清洗数据自动索引：
- 优先：`data/processed/processed_cleaning_{videoId}_*.json`（最新）
- 其次：`data/processed/processed_cleaning_*.json`（最新）
- 兼容：`douyin_comments_processed_{videoId}.json`、`douyin_comments_processed.json`

---

### 四、模块专属参数与要点
- cleaning
  - 参数：`--video-id`、`--limit`、`--test`、`--no-save`、`--no-report`、`--no-viz`
  - 输出：`data/processed/processed_cleaning[_{videoId}]_{timestamp}.json`
- time
  - 参数：`--use-cleaned-data`、`--video-id`、`--limit`、`--cleaned-data-path`、`--test`、`--no-save`、`--no-report`、`--no-viz`
  - 可视化：时间差直方/箱线、窗口分布饼图、密集时段条形
- like
  - 参数：同上（不含阈值类）
  - 可视化：点赞分布、区间饼图、父/子点赞散点、领袖/信号柱状
- sentiment
  - 参数（统一入口）：`--use-cleaned-data`、`--type local|aliyun(默认)`、`--video-id`、`--limit`、`--cleaned-data-path`、`--test`、`--sa-concurrency`(默认8)、`--sa-batch-size`(默认200)、`--sa-throttle-ms`(默认0)
  - 说明：统一入口会忽略 `--no-report/--no-viz` 对情感模块的透传
  - 直接运行模块文件时也支持以上并发参数
- similarity
  - 参数：通用 + `--similarity-threshold`(默认0.7) `--time-diff-threshold`(秒，默认3600)
  - 性能参数（模块内）：`--vector-batch-size`(默认100) `--vector-concurrency`(默认8) `--vector-throttle-ms`(默认0)
  - 判定：相似度>阈值 且 时间差<阈值 → 模仿性评论对

---

### 五、推荐流程（一步步）
1) 清洗：
```bash
python text_analysis/text_analysis_unified.py cleaning --video-id 7306437681045654834
```
2) 时间分析：
```bash
python text_analysis/text_analysis_unified.py time --use-cleaned-data --video-id 7306437681045654834
```
3) 点赞分析：
```bash
python text_analysis/text_analysis_unified.py like --use-cleaned-data --video-id 7306437681045654834
```
4) 情感分析（默认 aliyun）：
```bash
python text_analysis/text_analysis_unified.py sentiment --use-cleaned-data --type aliyun --video-id 7306437681045654834
```
5) 相似度分析（自定义阈值举例）：
```bash
python text_analysis/text_analysis_unified.py similarity --use-cleaned-data --video-id 7306437681045654834 --similarity-threshold 0.75 --time-diff-threshold 5400
```

---

### 六、按场景模板
- 最简（全量）：
  ```bash
  python text_analysis/text_analysis_unified.py cleaning
  python text_analysis/text_analysis_unified.py time --use-cleaned-data
  python text_analysis/text_analysis_unified.py like --use-cleaned-data
  python text_analysis/text_analysis_unified.py sentiment --use-cleaned-data --type aliyun
  python text_analysis/text_analysis_unified.py similarity --use-cleaned-data
  ```
- 快速测试（小样本+关闭可视化）：
  ```bash
  python text_analysis/text_analysis_unified.py cleaning --test
  python text_analysis/text_analysis_unified.py time --use-cleaned-data --test --no-viz
  python text_analysis/text_analysis_unified.py like --use-cleaned-data --test --no-viz
  python text_analysis/text_analysis_unified.py sentiment --use-cleaned-data --type local --test
  python text_analysis/text_analysis_unified.py similarity --use-cleaned-data --test --no-viz
  ```
- 指定视频与数据量：
  ```bash
  python text_analysis/text_analysis_unified.py cleaning --video-id 7306437681045654834 --limit 5000
  python text_analysis/text_analysis_unified.py time --use-cleaned-data --video-id 7306437681045654834 --limit 5000 --no-viz
  python text_analysis/text_analysis_unified.py like --use-cleaned-data --video-id 7306437681045654834 --limit 5000 --no-viz
  python text_analysis/text_analysis_unified.py sentiment --use-cleaned-data --type aliyun --video-id 7306437681045654834 --limit 5000
  python text_analysis/text_analysis_unified.py similarity --use-cleaned-data --video-id 7306437681045654834 --limit 5000 --no-viz
  ```

---

### 七、输出命名与定位（统一规范）
- 结果：`data/results/results_{module}[_{videoId}]_{YYYYMMDD_HHMMSS}.(csv|json)`
- 报告：`data/reports/reports_{module}[_{videoId}]_{YYYYMMDD_HHMMSS}.json`
- 可视化：`data/visualizations/visualizations_{module}[_{videoId}]_{YYYYMMDD_HHMMSS}.png`
- 清洗：`data/processed/processed_cleaning[_{videoId}]_{YYYYMMDD_HHMMSS}.json`
- 时间戳示例：`20250810_225641` → 2025-08-10 22:56:41（HHMMSS）
- 自动索引：按“清洗数据自动索引”规则解析最新清洗数据

---

### 八、常见问题（FAQ）
- 未找到清洗数据：无需传路径，保证 `processed_cleaning*.json` 存在即可；系统自动找最新
- 阿里云认证报错：检查 `NLP_AK_ENV/NLP_SK_ENV`，确认已开通 `alinlp`，区域默认 `cn-hangzhou`
- 数据库连接失败：检查 `config/db_config.py`、网络与账号
- 图表未生成：是否传了 `--no-viz`；空数据同样会输出 PNG（占位提示）

---

### 九、性能与精度建议
- 大数据：`--limit` 分批、`--no-viz` 提速
- 精度优先：sentiment 用 `aliyun`；similarity 适当收紧阈值
- 速度优先：sentiment 用 `local`；similarity 减小 `--limit`

---

### 十、常用命令速查
```bash
# 全流程
python text_analysis/text_analysis_unified.py cleaning --video-id 730...
python text_analysis/text_analysis_unified.py time --use-cleaned-data --video-id 730...
python text_analysis/text_analysis_unified.py like --use-cleaned-data --video-id 730...
python text_analysis/text_analysis_unified.py sentiment --use-cleaned-data --type aliyun --video-id 730...
python text_analysis/text_analysis_unified.py similarity --use-cleaned-data --video-id 730...

# 快测
python text_analysis/text_analysis_unified.py cleaning --test
python text_analysis/text_analysis_unified.py time --use-cleaned-data --test --no-viz
python text_analysis/text_analysis_unified.py like --use-cleaned-data --test --no-viz
python text_analysis/text_analysis_unified.py sentiment --use-cleaned-data --type local --test
python text_analysis/text_analysis_unified.py similarity --use-cleaned-data --test --no-viz
```


