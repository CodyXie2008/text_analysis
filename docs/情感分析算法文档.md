# ç¤¾äº¤åª’ä½“è¯„è®ºæƒ…æ„Ÿåˆ†æç®—æ³•æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ¨¡å—å®ç°äº†å¤šç§æƒ…æ„Ÿåˆ†ææ–¹æ³•ï¼Œç”¨äºåˆ†æç¤¾äº¤åª’ä½“è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ã€‚æ”¯æŒæ­£å‘ã€ä¸­æ€§ã€è´Ÿå‘ä¸‰ç§æƒ…æ„Ÿåˆ†ç±»ï¼Œå¹¶æä¾›ç½®ä¿¡åº¦è¯„ä¼°ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

1. **SentimentAnalyzer** - æƒ…æ„Ÿåˆ†æå™¨åŸºç±»
2. **DictionaryBasedAnalyzer** - åŸºäºè¯å…¸çš„åˆ†æå™¨
3. **BaiduNLPAnalyzer** - ç™¾åº¦NLP APIåˆ†æå™¨
4. **TencentCloudAnalyzer** - è…¾è®¯äº‘APIåˆ†æå™¨
5. **DeepSeekAnalyzer** - DeepSeek APIåˆ†æå™¨
6. **AliyunNLPAnalyzer** - é˜¿é‡Œäº‘NLP APIåˆ†æå™¨
7. **SentimentAnalysisManager** - åˆ†æç®¡ç†å™¨

### ç±»å›¾ç»“æ„

```
SentimentAnalyzer (åŸºç±»)
â”œâ”€â”€ DictionaryBasedAnalyzer
â”œâ”€â”€ BaiduNLPAnalyzer
â”œâ”€â”€ TencentCloudAnalyzer
â”œâ”€â”€ DeepSeekAnalyzer
â””â”€â”€ AliyunNLPAnalyzer

SentimentAnalysisManager (ç®¡ç†å™¨)
â””â”€â”€ ç®¡ç†å„ç§åˆ†æå™¨å®ä¾‹
```

## ğŸ”§ ç®—æ³•è¯¦è§£

### 1. è¯å…¸åŒ¹é…ç®—æ³•

#### 1.1 æƒ…æ„Ÿè¯å…¸æ„å»º

**æ­£å‘æƒ…æ„Ÿè¯**ï¼š
- åŸºç¡€è¯ï¼šå¥½ã€æ£’ã€èµã€ä¼˜ç§€ã€å®Œç¾ã€ç²¾å½©
- æƒ…æ„Ÿè¯ï¼šå–œæ¬¢ã€çˆ±ã€æ”¯æŒã€æ¨èã€æ»¡æ„ã€å¼€å¿ƒ
- ç½‘ç»œç”¨è¯­ï¼š666ã€ç‰›ã€ç¥ã€ç»äº†ã€æ— æ•Œã€çˆ†èµ

**è´Ÿå‘æƒ…æ„Ÿè¯**ï¼š
- åŸºç¡€è¯ï¼šå·®ã€çƒ‚ã€åƒåœ¾ã€ç³Ÿç³•ã€æ¶å¿ƒã€è®¨åŒ
- æƒ…æ„Ÿè¯ï¼šæ¨ã€çƒ¦ã€ç”Ÿæ°”ã€æ„¤æ€’ã€å¤±æœ›ã€ä¼¤å¿ƒ
- ç½‘ç»œç”¨è¯­ï¼šå‘ã€éª—ã€å‡ã€æ°´ã€æ— èŠã€æ²¡æ„æ€

**ä¸­æ€§æƒ…æ„Ÿè¯**ï¼š
- ä¸€èˆ¬ã€è¿˜è¡Œã€å‡‘åˆã€æ™®é€šã€æ­£å¸¸ã€æ ‡å‡†
- å¯ä»¥ã€ä¸é”™ã€è¿˜å¥½ã€é©¬é©¬è™è™ã€è¿‡å¾—å»

#### 1.2 å¦å®šè¯å¤„ç†

```python
negation_words = {
    'ä¸', 'æ²¡', 'æ— ', 'é', 'æœª', 'åˆ«', 'è«', 'å‹¿', 'æ¯‹', 'å¼—', 'å¦', 'å',
    'ä¸æ˜¯', 'æ²¡æœ‰', 'æ— ', 'ä¸', 'åˆ«', 'è«', 'å‹¿', 'æ¯‹', 'å¼—', 'å¦', 'å'
}
```

**å¦å®šè§„åˆ™**ï¼š
- æ£€æµ‹æƒ…æ„Ÿè¯å‰3ä¸ªä½ç½®å†…çš„å¦å®šè¯
- å¦å®šè¯ä¼šå°†æƒ…æ„Ÿææ€§åè½¬
- æ”¯æŒå¤šé‡å¦å®šï¼ˆè´Ÿè´Ÿå¾—æ­£ï¼‰

#### 1.3 ç¨‹åº¦å‰¯è¯å¤„ç†

```python
intensifier_words = {
    'éå¸¸': 2.0, 'ç‰¹åˆ«': 2.0, 'æå…¶': 2.0, 'ååˆ†': 2.0, 'å¾ˆ': 1.5, 'æŒº': 1.3,
    'æ¯”è¾ƒ': 1.2, 'æœ‰ç‚¹': 0.8, 'ç¨å¾®': 0.7, 'ç•¥å¾®': 0.7, 'å¤ª': 1.8, 'çœŸ': 1.5
}
```

**ç¨‹åº¦è§„åˆ™**ï¼š
- æ£€æµ‹æƒ…æ„Ÿè¯å‰2ä¸ªä½ç½®å†…çš„ç¨‹åº¦å‰¯è¯
- ç¨‹åº¦å‰¯è¯ä¼šæ”¾å¤§æˆ–ç¼©å°æƒ…æ„Ÿå¼ºåº¦
- æ”¯æŒå¤šé‡ç¨‹åº¦ä¿®é¥°

#### 1.4 æƒ…æ„Ÿå¾—åˆ†è®¡ç®—

```python
def calculate_sentiment_score(self, text: str) -> float:
    total_score = 0.0
    
    for i, word in enumerate(words):
        if word in self.sentiment_dict:
            score = self.sentiment_dict[word]
            
            # å¦å®šè¯æ•ˆæœ
            negation_effect = 1.0
            for j in range(max(0, i-3), i):
                if words[j] in self.negation_words:
                    negation_effect *= -1
            
            # ç¨‹åº¦å‰¯è¯æ•ˆæœ
            intensifier_effect = 1.0
            for j in range(max(0, i-2), i):
                if words[j] in self.intensifier_words:
                    intensifier_effect *= self.intensifier_words[words[j]]
            
            total_score += score * negation_effect * intensifier_effect
    
    # å½’ä¸€åŒ–å¤„ç†
    return total_score / len(words) if len(words) > 0 else 0.0
```

#### 1.5 æƒ…æ„Ÿåˆ†ç±»é˜ˆå€¼

```python
thresholds = {
    'positive': 0.3,   # æ­£å‘é˜ˆå€¼
    'negative': -0.3   # è´Ÿå‘é˜ˆå€¼
}
```

**åˆ†ç±»è§„åˆ™**ï¼š
- score â‰¥ 0.3 â†’ æ­£å‘
- score â‰¤ -0.3 â†’ è´Ÿå‘
- -0.3 < score < 0.3 â†’ ä¸­æ€§

### 2. APIé›†æˆç®—æ³•

#### 2.1 é˜¿é‡Œäº‘NLP API

**æœåŠ¡æ¦‚è¿°**ï¼š
æ ¹æ®[é˜¿é‡Œäº‘å®˜æ–¹æ–‡æ¡£](https://help.aliyun.com/document_detail/179345.html)ï¼Œé˜¿é‡Œäº‘NLPæƒ…æ„Ÿåˆ†æï¼ˆåŸºç¡€ç‰ˆ-é€šç”¨é¢†åŸŸï¼‰æœåŠ¡é’ˆå¯¹å¸¦æœ‰ä¸»è§‚æè¿°çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œå¯è‡ªåŠ¨åˆ¤æ–­è¯¥æ–‡æœ¬çš„æƒ…æ„Ÿæ­£è´Ÿå€¾å‘å¹¶ç»™å‡ºç›¸åº”çš„ç»“æœã€‚

**æ¥å£ä¿¡æ¯**ï¼š
- **æ¥å£åç§°**: GetSaChGeneral
- **æœåŠ¡ä»£ç **: alinlp
- **æ”¯æŒè¯­è¨€**: ä¸­æ–‡
- **æ”¯æŒé¢†åŸŸ**: é€šç”¨é¢†åŸŸ
- **æ–‡æœ¬é•¿åº¦**: ä¸è¶…è¿‡1000å­—ç¬¦
- **æ¥å£åœ°å€**: `https://alinlp.cn-hangzhou.aliyuncs.com/`

**è®¤è¯æ–¹å¼**ï¼š
- AccessKey ID å’Œ AccessKey Secret
- HMAC-SHA1 ç­¾åè®¤è¯
- æ”¯æŒå¤šç§åœ°åŸŸèŠ‚ç‚¹

**ç­¾åç®—æ³•**ï¼š
```python
def _generate_signature(self, method: str, path: str, params: Dict, headers: Dict) -> str:
    # æ„å»ºè§„èŒƒåŒ–è¯·æ±‚å­—ç¬¦ä¸²
    canonicalized_query_string = "&".join([f"{k}={v}" for k, v in sorted(params.items())])
    canonicalized_headers = "&".join([f"{k.lower()}:{v}" for k, v in sorted(headers.items())])
    
    string_to_sign = f"{method}\n{path}\n{canonicalized_query_string}\n{canonicalized_headers}"
    
    # ä½¿ç”¨HMAC-SHA1è®¡ç®—ç­¾å
    signature = base64.b64encode(
        hmac.new(
            self.access_key_secret.encode('utf-8'),
            string_to_sign.encode('utf-8'),
            hashlib.sha1
        ).digest()
    ).decode('utf-8')
    
    return signature
```

**è¯·æ±‚å‚æ•°**ï¼š
```python
request_params = {
    'Action': 'SentimentAnalysis',
    'Version': '2018-04-08',
    'Format': 'JSON',
    'Timestamp': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
    'SignatureMethod': 'HMAC-SHA1',
    'SignatureVersion': '1.0',
    'SignatureNonce': str(int(time.time() * 1000)),
    'AccessKeyId': access_key_id,
    'Text': text,
    'ServiceCode': 'alinlp'
}
```

**ç»“æœå¤„ç†**ï¼š
```python
# è§£æé˜¿é‡Œäº‘è¿”å›ç»“æœ
if 'Data' in result and 'Sentiment' in result['Data']:
    sentiment_data = result['Data']['Sentiment']
    
    sentiment_mapping = {
        'positive': SentimentType.POSITIVE.value,
        'negative': SentimentType.NEGATIVE.value,
        'neutral': SentimentType.NEUTRAL.value
    }
    
    sentiment = sentiment_mapping.get(sentiment_data.get('Sentiment', ''), SentimentType.NEUTRAL.value)
    score = sentiment_data.get('Score', 0.0)
    confidence = sentiment_data.get('Confidence', 0.0)
```

**ä¼˜åŠ¿ç‰¹ç‚¹**ï¼š
- åŸºäºæµ·é‡å¤§æ•°æ®è®­ç»ƒ
- æ”¯æŒå¤šè¯­è¨€åˆ†æ
- é«˜ç²¾åº¦æƒ…æ„Ÿè¯†åˆ«
- ä¼ä¸šçº§æœåŠ¡ç¨³å®šæ€§
- ä¸°å¯Œçš„è¡Œä¸šåº”ç”¨åœºæ™¯

#### 2.2 ç™¾åº¦NLP API

**æ¥å£åœ°å€**ï¼š`https://aip.baidubce.com/rpc/2.0/nlp/v1/sentiment_classify`

**è®¤è¯æµç¨‹**ï¼š
1. è·å–access_token
2. ä½¿ç”¨tokenè°ƒç”¨æƒ…æ„Ÿåˆ†ææ¥å£
3. è§£æè¿”å›çš„æ¦‚ç‡åˆ†å¸ƒ

**ç»“æœå¤„ç†**ï¼š
```python
# è®¡ç®—æƒ…æ„Ÿå¾—åˆ†
score = positive_prob - negative_prob

# ç¡®å®šæƒ…æ„Ÿç±»å‹
if positive_prob > 0.6:
    sentiment = "positive"
elif negative_prob > 0.6:
    sentiment = "negative"
else:
    sentiment = "neutral"
```

#### 2.2 DeepSeek API

**æ¥å£åœ°å€**ï¼š`https://api.deepseek.com/v1/chat/completions`

**Promptè®¾è®¡**ï¼š
```
è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼Œåªè¿”å›JSONæ ¼å¼ç»“æœï¼š
æ–‡æœ¬ï¼š{text}

è¯·è¿”å›æ ¼å¼ï¼š
{
    "sentiment": "positive/neutral/negative",
    "score": 0.0-1.0ä¹‹é—´çš„æ•°å€¼,
    "confidence": 0.0-1.0ä¹‹é—´çš„ç½®ä¿¡åº¦
}
```

**ç»“æœè§£æ**ï¼š
- è§£æJSONå“åº”
- éªŒè¯æ ¼å¼æ­£ç¡®æ€§
- æå–æƒ…æ„Ÿä¿¡æ¯

### 3. ç½®ä¿¡åº¦è®¡ç®—

#### 3.1 è¯å…¸åˆ†æç½®ä¿¡åº¦

```python
def calculate_confidence(self, score: float) -> float:
    abs_score = abs(score)
    if abs_score >= 0.5:
        return min(0.95, 0.7 + abs_score * 0.5)
    elif abs_score >= 0.2:
        return 0.5 + abs_score * 0.4
    else:
        return 0.3 + abs_score * 0.4
```

**ç½®ä¿¡åº¦è§„åˆ™**ï¼š
- å¾—åˆ†ç»å¯¹å€¼è¶Šå¤§ï¼Œç½®ä¿¡åº¦è¶Šé«˜
- æœ€é«˜ç½®ä¿¡åº¦é™åˆ¶åœ¨0.95
- æœ€ä½ç½®ä¿¡åº¦ä¸ä½äº0.3

#### 3.2 APIåˆ†æç½®ä¿¡åº¦

- **é˜¿é‡Œäº‘NLP**ï¼šç›´æ¥ä½¿ç”¨APIè¿”å›çš„ç½®ä¿¡åº¦
- **ç™¾åº¦NLP**ï¼šä½¿ç”¨æœ€å¤§æ¦‚ç‡å€¼ä½œä¸ºç½®ä¿¡åº¦
- **DeepSeek**ï¼šç›´æ¥ä½¿ç”¨APIè¿”å›çš„ç½®ä¿¡åº¦

## ğŸ“Š æ•°æ®æµç¨‹

### 1. æ•°æ®è¾“å…¥

```python
# ä»æ•°æ®åº“è·å–è¯„è®º
query = """
SELECT id, content, user_id, created_time, platform, likes_count
FROM comments 
WHERE created_time BETWEEN %s AND %s
ORDER BY created_time DESC
LIMIT %s
"""
```

### 2. æ–‡æœ¬é¢„å¤„ç†

```python
def preprocess_text(self, text: str) -> str:
    # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s]', '', text)
    # å»é™¤å¤šä½™ç©ºç™½
    text = re.sub(r'\s+', ' ', text).strip()
    return text
```

### 3. æƒ…æ„Ÿåˆ†æ

```python
# åˆ†æå•ä¸ªæ–‡æœ¬
result = analyzer.analyze_sentiment(text)

# æ‰¹é‡åˆ†æ
results = manager.analyze_batch(texts)
```

### 4. ç»“æœè¾“å‡º

```python
# ä¿å­˜è¯¦ç»†ç»“æœ
df.to_csv(output_file, index=False, encoding='utf-8-sig')

# ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
report = {
    'analysis_time': datetime.now().isoformat(),
    'analyzer_type': analyzer_type,
    'total_comments': len(df),
    'statistics': stats,
    'sentiment_distribution': sentiment_dist,
    'confidence_analysis': confidence_stats
}
```

## âš™ï¸ é…ç½®å‚æ•°

### 1. åˆ†æå™¨é…ç½®

```python
# è¯å…¸åˆ†æå™¨
analyzer = DictionaryBasedAnalyzer()
analyzer.thresholds = {
    'positive': 0.3,
    'negative': -0.3
}

# APIåˆ†æå™¨
analyzer = AliyunNLPAnalyzer(access_key_id="your_key", access_key_secret="your_secret")
analyzer = BaiduNLPAnalyzer(api_key="your_key", secret_key="your_secret")
analyzer = DeepSeekAnalyzer(api_key="your_key", base_url="https://api.deepseek.com")
```

### 2. ç®¡ç†å™¨é…ç½®

```python
# åˆ›å»ºç®¡ç†å™¨
manager = SentimentAnalysisManager(
    analyzer_type="dictionary",  # æˆ– "baidu", "deepseek", "aliyun"
    api_key="your_key",
    secret_key="your_secret"
)
```

### 3. æ•°æ®åº“æŸ¥è¯¢é…ç½®

```python
# æ—¶é—´èŒƒå›´
start_time = datetime.now() - timedelta(days=7)
end_time = datetime.now()

# å¹³å°è¿‡æ»¤
platform = "douyin"  # æˆ– "weibo", "zhihu", "bilibili"

# æ•°é‡é™åˆ¶
limit = 1000
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†

```python
# åˆ†æ‰¹å¤„ç†å¤§é‡æ•°æ®
batch_size = 100
for i in range(0, len(texts), batch_size):
    batch = texts[i:i+batch_size]
    results.extend(manager.analyze_batch(batch))
```

### 2. ç¼“å­˜æœºåˆ¶

```python
# ç™¾åº¦NLP tokenç¼“å­˜
if self.access_token and time.time() < self.token_expire_time:
    return self.access_token
```

### 3. é”™è¯¯å¤„ç†

```python
# APIè°ƒç”¨å¤±è´¥æ—¶é™çº§åˆ°è¯å…¸åˆ†æ
try:
    result = api_analyzer.analyze_sentiment(text)
except Exception as e:
    logger.warning(f"APIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨è¯å…¸åˆ†æ: {e}")
    result = dictionary_analyzer.analyze_sentiment(text)
```

## ğŸ” è¯„ä¼°æŒ‡æ ‡

### 1. å‡†ç¡®ç‡è¯„ä¼°

```python
# è®¡ç®—å„ç±»åˆ«å‡†ç¡®ç‡
accuracy_metrics = {
    'positive_accuracy': positive_correct / positive_total,
    'negative_accuracy': negative_correct / negative_total,
    'neutral_accuracy': neutral_correct / neutral_total,
    'overall_accuracy': total_correct / total_samples
}
```

### 2. ç½®ä¿¡åº¦åˆ†æ

```python
confidence_analysis = {
    'mean_confidence': df['confidence'].mean(),
    'std_confidence': df['confidence'].std(),
    'high_confidence_ratio': (df['confidence'] > 0.8).mean(),
    'low_confidence_ratio': (df['confidence'] < 0.5).mean()
}
```

### 3. åˆ†å¸ƒç»Ÿè®¡

```python
sentiment_distribution = {
    'positive_ratio': positive_count / total_count,
    'negative_ratio': negative_count / total_count,
    'neutral_ratio': neutral_count / total_count
}
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€ä½¿ç”¨

```python
# åˆ›å»ºåˆ†æå™¨
manager = SentimentAnalysisManager("dictionary")

# åˆ†æå•ä¸ªæ–‡æœ¬
result = manager.analyze_text("è¿™ä¸ªè§†é¢‘çœŸçš„å¾ˆæ£’ï¼")
print(result)  # {'sentiment': 'positive', 'score': 0.8, 'confidence': 0.85}

# æ‰¹é‡åˆ†æ
texts = ["å¾ˆå¥½", "å¾ˆå·®", "ä¸€èˆ¬"]
results = manager.analyze_batch(texts)
```

### 2. æ•°æ®åº“åˆ†æ

```python
# è¿æ¥æ•°æ®åº“
conn = get_db_conn()

# åˆ†æè¯„è®º
df = manager.analyze_comments_from_db(
    conn=conn,
    start_time=start_time,
    end_time=end_time,
    limit=1000
)

# ä¿å­˜ç»“æœ
manager.save_results(df, "sentiment_results.csv")
manager.generate_report(df, "sentiment_report.json")
```

### 3. APIä½¿ç”¨

```python
# ä½¿ç”¨é˜¿é‡Œäº‘NLP
manager = SentimentAnalysisManager(
    "aliyun",
    access_key_id="your_aliyun_access_key_id",
    access_key_secret="your_aliyun_access_key_secret",
    endpoint="nlp.cn-hangzhou.aliyuncs.com"
)

# ä½¿ç”¨ç™¾åº¦NLP
manager = SentimentAnalysisManager(
    "baidu",
    api_key="your_baidu_api_key",
    secret_key="your_baidu_secret_key"
)

# ä½¿ç”¨DeepSeek
manager = SentimentAnalysisManager(
    "deepseek",
    api_key="your_deepseek_api_key"
)
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. APIè°ƒç”¨å¤±è´¥

**é—®é¢˜**ï¼šAPIå¯†é’¥æ— æ•ˆæˆ–ç½‘ç»œé—®é¢˜
**è§£å†³**ï¼šæ£€æŸ¥APIå¯†é’¥ï¼Œç½‘ç»œè¿æ¥ï¼Œæˆ–é™çº§åˆ°è¯å…¸åˆ†æ

### 2. æƒ…æ„Ÿåˆ†ç±»ä¸å‡†ç¡®

**é—®é¢˜**ï¼šè¯å…¸è¦†ç›–ä¸å…¨æˆ–é˜ˆå€¼è®¾ç½®ä¸å½“
**è§£å†³**ï¼šæ‰©å……æƒ…æ„Ÿè¯å…¸ï¼Œè°ƒæ•´åˆ†ç±»é˜ˆå€¼

### 3. å¤„ç†é€Ÿåº¦æ…¢

**é—®é¢˜**ï¼šå¤§é‡æ•°æ®æˆ–APIè°ƒç”¨å»¶è¿Ÿ
**è§£å†³**ï¼šä½¿ç”¨æ‰¹é‡å¤„ç†ï¼Œå¢åŠ å¹¶å‘ï¼Œæˆ–ä½¿ç”¨æœ¬åœ°è¯å…¸åˆ†æ

### 4. å†…å­˜å ç”¨é«˜

**é—®é¢˜**ï¼šå¤§é‡æ•°æ®ä¸€æ¬¡æ€§åŠ è½½
**è§£å†³**ï¼šåˆ†æ‰¹å¤„ç†ï¼ŒåŠæ—¶é‡Šæ”¾å†…å­˜

## ğŸ“ æ‰©å±•å»ºè®®

### 1. è¯å…¸æ‰©å±•

- æ·»åŠ æ›´å¤šç½‘ç»œç”¨è¯­
- æ”¯æŒè¡¨æƒ…ç¬¦å·æƒ…æ„Ÿåˆ†æ
- å¢åŠ è¡Œä¸šä¸“ä¸šè¯æ±‡

### 2. ç®—æ³•ä¼˜åŒ–

- å®ç°æ·±åº¦å­¦ä¹ æ¨¡å‹
- æ”¯æŒå¤šè¯­è¨€æƒ…æ„Ÿåˆ†æ
- å¢åŠ æƒ…æ„Ÿå¼ºåº¦ç»†åˆ†

### 3. åŠŸèƒ½å¢å¼º

- æ”¯æŒå®æ—¶æƒ…æ„Ÿåˆ†æ
- å¢åŠ æƒ…æ„Ÿè¶‹åŠ¿åˆ†æ
- æ”¯æŒè‡ªå®šä¹‰æƒ…æ„Ÿåˆ†ç±»

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [æ•°æ®æ¸…æ´—ç®—æ³•è§„åˆ™è¯¦è§£](./æ•°æ®æ¸…æ´—ç®—æ³•è§„åˆ™è¯¦è§£.md)
- [ç‚¹èµäº’åŠ¨åˆ†æç®—æ³•æ–‡æ¡£](./ç‚¹èµäº’åŠ¨åˆ†æç®—æ³•æ–‡æ¡£.md)
- [ä»ä¼—å¿ƒç†æ—¶é—´åˆ†æåŠŸèƒ½ç®—æ³•æ–‡æ¡£](./ä»ä¼—å¿ƒç†æ—¶é—´åˆ†æåŠŸèƒ½ç®—æ³•æ–‡æ¡£.md)
- [å¿«é€Ÿä½¿ç”¨æŒ‡å—](./å¿«é€Ÿä½¿ç”¨æŒ‡å—.md) 