
# 🎯 抖音评论数据预处理模块算法文档

## 一、模块目标

本模块旨在对来自 `douyin_aweme_comment` 表的原始评论数据进行标准化清洗与结构化处理，构建可供后续情感分析、从众行为建模的统一数据集。

模块主要功能包括：

1. 数据加载与字段标准化；
    
2. 评论文本清洗；
    
3. 时间格式转化；
    
4. 评论树（父子层级）构建；
    
5. 数据结构序列化为 JSON；
    
6. 支持灵活参数配置（如最小长度、停用词表等）。
    

---

## 二、数据输入

### 数据来源

来自 MySQL 数据表 `douyin_aweme_comment`，示例字段如下：

| 字段名                 | 说明              |
| ------------------- | --------------- |
| `id`                | 自增主键            |
| `comment_id`        | 评论唯一标识符         |
| `aweme_id`          | 视频ID            |
| `parent_comment_id` | 父评论ID（为空则为一级评论） |
| `content`           | 评论文本内容          |
| `create_time`       | 评论时间戳（Unix秒级）   |
| `like_count`        | 点赞数量（字符串形式）     |
| `sub_comment_count` | 子评论数            |
| `user_id`           | 用户ID            |
| `nickname`          | 用户昵称            |
| `user_signature`    | 用户个性签名          |
| `ip_location`       | IP属地            |
| ...                 | 其余保留字段          |

### SQL 查询

```sql
SELECT
    id, comment_id, aweme_id, parent_comment_id, content, create_time,
    like_count, sub_comment_count, user_id, nickname, user_signature, ip_location
FROM douyin_aweme_comment
WHERE content IS NOT NULL;
```

---

## 三、处理流程概述

```
            ┌─────────────┐
            │  数据加载   │
            └──────┬──────┘
                   ↓
            ┌─────────────┐
            │  数据清洗   │
            │ (去噪/空值) │
            └──────┬──────┘
                   ↓
            ┌─────────────┐
            │  文本处理   │
            │ (分词/去停用)│
            └──────┬──────┘
                   ↓
            ┌─────────────┐
            │ 时间格式化  │
            └──────┬──────┘
                   ↓
            ┌─────────────┐
            │ 评论树构建  │
            └──────┬──────┘
                   ↓
            ┌─────────────┐
            │ JSON导出    │
            └─────────────┘
```

---

## 四、算法设计与实现步骤

### Step 1. 数据加载

- 使用 `pandas.read_sql` 从 MySQL 数据库中读取数据；
    
- 所有字段均保留（包括 `ip_location`、`avatar`、`user_signature` 等），确保数据完整性；
    
- 自动将 `like_count`、`sub_comment_count` 转换为 `int`。
    

```python
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine("mysql+pymysql://user:password@localhost:3306/dbname")
df = pd.read_sql("""
SELECT * FROM douyin_aweme_comment WHERE content IS NOT NULL
""", engine)
```

---

### Step 2. 数据清洗

#### 2.1 删除无效内容

过滤空字符串、仅包含表情/空格/广告的评论：

```python
df = df[df['content'].str.strip().str.len() > min_length]
```

参数：

- `min_length`: 默认 `2`（可在配置文件中调整）
    

#### 2.2 去除垃圾信息

可定义黑名单或广告关键词：

```python
ban_words = ['关注我', '点击', '链接', '广告', '代购']
df = df[~df['content'].apply(lambda x: any(w in x for w in ban_words))]
```

---

### Step 3. 文本预处理（jieba 分词）

1. 使用 `jieba.lcut()` 分词；
    
2. 去除停用词；
    
3. 支持自定义停用词表路径与词典扩展。
    

```python
import jieba

stopwords = set(open("stopwords.txt", encoding='utf8').read().splitlines())

def clean_text(text):
    words = jieba.lcut(text)
    return [w for w in words if w not in stopwords and len(w.strip()) > 1]

df['tokens'] = df['content'].apply(clean_text)
```

---

### Step 4. 时间格式化

将 Unix 时间戳转化为可读格式：

```python
import datetime

df['datetime'] = df['create_time'].apply(
    lambda t: datetime.datetime.fromtimestamp(int(t)).strftime('%Y-%m-%d %H:%M:%S')
)
```

---

### Step 5. 评论树构建算法

**思路：**  
每条评论根据 `parent_comment_id` 归类到其父节点下；若为空则为根评论。

```python
from collections import defaultdict

def build_comment_tree(df):
    tree = defaultdict(list)
    for _, row in df.iterrows():
        parent = row['parent_comment_id'] or 'root'
        tree[parent].append(row.to_dict())
    return tree
```

构建后格式：

```json
{
  "root": [
    {
      "comment_id": "12345",
      "content": "哈哈哈太好笑了",
      "children": [
        {"comment_id": "54321", "content": "确实哈哈哈哈"}
      ]
    }
  ]
}
```

---

### Step 6. 数据输出

将每个视频 (`aweme_id`) 的评论树分别输出为 JSON 文件：
文件命名格式是视频id+时间戳.json

```python
import json
import os

output_dir = "./processed_json"
os.makedirs(output_dir, exist_ok=True)

for aweme_id, group in df.groupby('aweme_id'):
    comment_tree = build_comment_tree(group)
    with open(f"{output_dir}/{aweme_id}.json", "w", encoding="utf8") as f:
        json.dump(comment_tree, f, ensure_ascii=False, indent=2)
```

---

## 五、模块参数配置（集中管理）

所有参数可统一配置在 `config.yaml`：

```yaml
text:
  min_length: 2
  stopwords_path: "stopwords.txt"
  jieba_dict: "userdict.txt"
filter:
  stopwords: ["关注我", "广告", "代购"]
output:
  json_path: "./processed_json"
```

---

## 六、输出结构说明

每个视频对应一个 JSON 文件，字段包括：

|字段|类型|说明|
|---|---|---|
|`comment_id`|str|评论唯一ID|
|`parent_comment_id`|str|父评论ID|
|`content`|str|原始文本|
|`tokens`|list|分词结果|
|`datetime`|str|格式化时间|
|`like_count`|int|点赞数|
|`user_id`|str|用户ID|
|`nickname`|str|昵称|
|`ip_location`|str|IP属地|
|`children`|list|子评论|


---

## 八、示例输出

```json
{
  "root": [
    {
      "comment_id": "c001",
      "content": "太搞笑了哈哈哈",
      "tokens": ["太", "搞笑", "哈哈哈"],
      "datetime": "2025-10-18 15:23:11",
      "like_count": 123,
      "ip_location": "广东",
      "children": [
        {
          "comment_id": "c002",
          "content": "确实",
          "tokens": ["确实"],
          "datetime": "2025-10-18 15:30:05",
          "like_count": 12
        }
      ]
    }
  ]
}
```
