# 抖音评论数据清洗算法规则详解

## 概述
本文档详细说明了`data_preparation_and_cleaning.py`中实现的所有数据清洗算法和规则，包括数据准备、过滤、清洗和预处理等各个阶段的具体实现。

## 一、整体流程架构

### 1.1 处理阶段划分
```
第一阶段：数据准备（提取原始数据）
    ↓
第二阶段：数据过滤（垃圾评论过滤）
    ↓
第三阶段：数据清洗（文本预处理）
    ↓
第四阶段：数据分布分析（统计分析）
```

### 1.2 核心类结构
- **CommentDataProcessor**: 主要处理类
- **方法分类**:
  - 数据获取: `get_raw_comments()`, `get_filtered_comments()`
  - 数据过滤: `is_spam_comment()`, `filter_spam_comments()`
  - 数据清洗: `clean_text()`, `segment_text()`
  - 数据分析: `analyze_data_distribution()`, `analyze_filtering_effect()`

## 二、第一阶段：数据准备算法

### 2.1 原始数据提取规则

#### 算法：`get_raw_comments()`
**目的**: 从数据库提取原始评论数据，不进行任何内容过滤

**SQL查询规则**:
```sql
SELECT 
    comment_id, aweme_id, parent_comment_id, content, create_time, 
    like_count, sub_comment_count, user_id, nickname, user_signature
FROM douyin_aweme_comment
WHERE content IS NOT NULL
```

**提取字段说明**:
- `comment_id`: 评论唯一标识符
- `aweme_id`: 视频ID，用于关联视频信息
- `parent_comment_id`: 父评论ID，用于识别评论层级关系
- `content`: 评论文本内容
- `create_time`: Unix时间戳，评论创建时间
- `like_count`: 点赞数量
- `sub_comment_count`: 子评论数量
- `user_id`: 用户ID
- `nickname`: 用户昵称
- `user_signature`: 用户签名

**时间过滤规则**（可选）:
```python
if start_time:
    start_timestamp = int(start_time.timestamp())
    base_sql += f" AND create_time >= {start_timestamp}"

if end_time:
    end_timestamp = int(end_time.timestamp())
    base_sql += f" AND create_time <= {end_timestamp}"
```

**示例**:
```python
# 提取最近30天的数据
start_time = datetime.now() - timedelta(days=30)
df_raw = processor.get_raw_comments(conn, start_time=start_time)

# 提取所有历史数据
df_raw = processor.get_raw_comments(conn)  # 不传时间参数
```

## 三、第二阶段：数据过滤算法

### 3.1 垃圾评论识别算法

#### 算法：`is_spam_comment(content, user_signature)`
**目的**: 识别并过滤垃圾评论、广告评论、机器人评论等低质量内容

#### 3.1.1 内容长度检查
**规则**: 内容长度小于5个字符的评论被过滤
```python
if len(content.strip()) < 5:
    return True
```

**示例**:
```python
# 会被过滤的评论
"666"           # 长度=3 < 5
"好"            # 长度=1 < 5
"👍"            # 长度=1 < 5

# 不会被过滤的评论
"真不错"        # 长度=3 < 5，但strip后可能更短
"这个视频很棒"   # 长度=6 >= 5
```

#### 3.1.2 特殊字符比例检查
**规则**: 特殊字符比例超过60%的评论被过滤
```python
special_char_ratio = len(re.findall(r'[^\u4e00-\u9fa5a-zA-Z0-9\s]', content)) / len(content)
if special_char_ratio > 0.6:
    return True
```

**正则表达式说明**:
- `[^\u4e00-\u9fa5a-zA-Z0-9\s]`: 匹配非中文、非英文、非数字、非空白字符
- `\u4e00-\u9fa5`: 中文字符范围
- `a-zA-Z`: 英文字母
- `0-9`: 数字
- `\s`: 空白字符

**示例**:
```python
# 会被过滤的评论
"🎉🎊🎈🎁🎂"     # 特殊字符比例=100% > 60%
"666666666"     # 特殊字符比例=0% <= 60%
"真棒👍👍👍"     # 特殊字符比例=50% <= 60%

# 不会被过滤的评论
"这个视频真不错！"  # 特殊字符比例=10% <= 60%
"支持一下😊"      # 特殊字符比例=20% <= 60%
```

#### 3.1.3 广告关键词检查
**规则**: 包含广告关键词的评论被过滤

**关键词列表**:
```python
ad_keywords = [
    '加微信', '加qq', '加群', '私信', '联系我', '合作', '推广', '广告',
    '赚钱', '兼职', '代理', '加盟', '招商', '投资', '理财', '贷款',
    '免费领取', '限时优惠', '点击链接', '扫码关注', '关注公众号'
]
```

**检查算法**:
```python
content_lower = content.lower()
for keyword in ad_keywords:
    if keyword in content_lower:
        return True
```

**示例**:
```python
# 会被过滤的评论
"加微信123456"           # 包含"加微信"
"想赚钱的私信我"         # 包含"赚钱"和"私信"
"免费领取优惠券"         # 包含"免费领取"
"扫码关注公众号"         # 包含"扫码关注"和"公众号"

# 不会被过滤的评论
"这个视频真不错"         # 不包含任何广告关键词
"我想学习这个技能"       # 不包含任何广告关键词
"支持一下，继续加油"     # 不包含任何广告关键词
```

#### 3.1.4 重复字符检查
**规则**: 重复字符过多的评论被过滤
```python
if len(set(content)) < len(content) * 0.2:
    return True
```

**算法说明**: 如果去重后的字符数少于原字符数的20%，则认为重复字符过多

**示例**:
```python
# 会被过滤的评论
"666666666666"          # 去重后="6", 比例=1/12=8.3% < 20%
"哈哈哈哈哈哈"          # 去重后="哈哈", 比例=2/6=33.3% > 20%
"！！！！！！！！"        # 去重后="！", 比例=1/8=12.5% < 20%

# 不会被过滤的评论
"这个视频真不错"        # 去重后="这个视频真不错", 比例=7/7=100% > 20%
"支持一下，继续加油"    # 去重后="支持一下，继续加油", 比例=8/8=100% > 20%
```

#### 3.1.5 用户签名检查
**规则**: 用户签名异常（过长或包含大量数字）的评论被过滤
```python
if user_signature:
    if len(user_signature) > 100:
        return True
    if re.search(r'[0-9]{8,}', user_signature):
        return True
```

**检查条件**:
1. 签名长度超过100个字符
2. 签名中包含8个或更多连续数字

**示例**:
```python
# 会被过滤的评论
user_signature = "这是一个非常长的用户签名，超过了100个字符的限制，应该被过滤掉..."  # 长度>100
user_signature = "微信：12345678"  # 包含8个连续数字

# 不会被过滤的评论
user_signature = "热爱生活"        # 长度=4 <= 100，无连续数字
user_signature = "微信：1234567"   # 长度=8 <= 100，连续数字=7 < 8
```

### 3.2 过滤效果统计
**算法**: `filter_spam_comments(df)`
**功能**: 批量应用垃圾评论过滤规则并统计过滤效果

**统计指标**:
- 过滤前数据量
- 过滤后数据量
- 过滤掉的垃圾评论数量
- 过滤率

## 四、第三阶段：数据清洗算法

### 4.1 文本清洗算法

#### 算法：`clean_text(text)`
**目的**: 对评论文本进行标准化清洗，去除无用信息

#### 4.1.1 HTML标签去除
**规则**: 去除所有HTML标签
```python
text = re.sub(r'<[^>]+>', '', text)
```

**正则表达式说明**:
- `<[^>]+>`: 匹配HTML标签
- `<`: 开始标签
- `[^>]+`: 一个或多个非>字符
- `>`: 结束标签

**示例**:
```python
# 输入
"<b>这个视频</b>真不错"

# 输出
"这个视频真不错"
```

#### 4.1.2 URL链接去除
**规则**: 去除所有HTTP/HTTPS链接
```python
text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
```

**正则表达式说明**:
- `http[s]?://`: 匹配http或https协议
- `(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+`: 匹配URL字符

**示例**:
```python
# 输入
"这个视频很棒，链接：https://www.douyin.com/video/123456"

# 输出
"这个视频很棒，链接："
```

#### 4.1.3 方括号内容去除
**规则**: 去除方括号及其内容（如表情符号标签）
```python
text = re.sub(r'\[[^\]]*\]', '', text)
```

**正则表达式说明**:
- `\[[^\]]*\]`: 匹配方括号及其内容
- `\[`: 左方括号
- `[^\]]*`: 零个或多个非右方括号字符
- `\]`: 右方括号

**示例**:
```python
# 输入
"这个视频真不错[666][比心][点赞]"

# 输出
"这个视频真不错"
```

#### 4.1.4 空白字符标准化
**规则**: 将多个连续空白字符替换为单个空格，并去除首尾空白
```python
text = re.sub(r'\s+', ' ', text).strip()
```

**正则表达式说明**:
- `\s+`: 匹配一个或多个空白字符
- `strip()`: 去除首尾空白字符

**示例**:
```python
# 输入
"  这个    视频   真不错  "

# 输出
"这个 视频 真不错"
```

#### 4.1.5 字符过滤
**规则**: 只保留中文、英文、数字、中文标点和空白字符
```python
text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s\u3000-\u303f\uff00-\uffef]', '', text)
```

**字符范围说明**:
- `\u4e00-\u9fa5`: 中文字符
- `a-zA-Z`: 英文字母
- `0-9`: 数字
- `\s`: 空白字符
- `\u3000-\u303f`: 中文标点符号（全角）
- `\uff00-\uffef`: 全角字符

**示例**:
```python
# 输入
"这个视频真不错！👍🎉"

# 输出
"这个视频真不错！"
```

### 4.2 中文分词算法

#### 算法：`segment_text(text)`
**目的**: 对清洗后的文本进行中文分词处理

**分词工具**: jieba中文分词库
**算法**: `jieba.lcut(text)`

**分词示例**:
```python
# 输入
"这个视频真不错"

# 分词结果
['这个', '视频', '真', '不错']

# 去除停用词后
['视频', '不错']  # "这个"和"真"被识别为停用词
```

**停用词过滤**:
```python
words = [word for word in words if word not in self.stop_words and len(word.strip()) > 0]
```

**停用词示例**:
```python
stop_words = {
    '的', '了', '在', '是', '我', '有', '和', '就', '不', '人', '都', 
    '一', '一个', '上', '也', '很', '到', '说', '要', '去', '你', 
    '会', '着', '没有', '看', '好', '自己', '这'
}
```

### 4.3 时间格式转换算法

#### 算法：时间格式转换
**目的**: 将Unix时间戳转换为可读的时间格式

**处理步骤**:
```python
# 1. 转换为datetime对象
df['create_time_dt'] = pd.to_datetime(df['create_time'], unit='s')

# 2. 格式化为字符串
df['create_time_str'] = df['create_time_dt'].dt.strftime('%Y-%m-%d %H:%M:%S')
```

**示例**:
```python
# 输入时间戳: 1640995200
# 输出datetime: 2022-01-01 00:00:00
# 输出字符串: "2022-01-01 00:00:00"
```

## 五、第四阶段：数据分析算法

### 5.1 数据分布分析

#### 算法：`analyze_data_distribution(conn, start_time, end_time)`
**目的**: 分析数据库中评论数据的分布特征

#### 5.1.1 总体数据统计
**SQL查询**:
```sql
SELECT COUNT(*) as total FROM douyin_aweme_comment
```

**统计指标**: 数据库总评论数

#### 5.1.2 时间分布分析
**SQL查询**:
```sql
SELECT 
    DATE(FROM_UNIXTIME(create_time)) as date,
    COUNT(*) as count
FROM douyin_aweme_comment
WHERE create_time IS NOT NULL
GROUP BY DATE(FROM_UNIXTIME(create_time))
ORDER BY date DESC
LIMIT 10
```

**统计指标**: 最近10天每日评论数量

#### 5.1.3 内容长度分布
**SQL查询**:
```sql
SELECT 
    CASE 
        WHEN CHAR_LENGTH(content) < 10 THEN '0-9字符'
        WHEN CHAR_LENGTH(content) < 20 THEN '10-19字符'
        WHEN CHAR_LENGTH(content) < 50 THEN '20-49字符'
        WHEN CHAR_LENGTH(content) < 100 THEN '50-99字符'
        ELSE '100+字符'
    END as length_range,
    COUNT(*) as count
FROM douyin_aweme_comment
WHERE content IS NOT NULL
GROUP BY length_range
```

**分布区间**:
- 0-9字符: 短评论
- 10-19字符: 较短评论
- 20-49字符: 中等长度评论
- 50-99字符: 较长评论
- 100+字符: 长评论

#### 5.1.4 点赞数分布
**SQL查询**:
```sql
SELECT 
    CASE 
        WHEN CAST(like_count AS UNSIGNED) = 0 THEN '0点赞'
        WHEN CAST(like_count AS UNSIGNED) < 5 THEN '1-4点赞'
        WHEN CAST(like_count AS UNSIGNED) < 20 THEN '5-19点赞'
        WHEN CAST(like_count AS UNSIGNED) < 100 THEN '20-99点赞'
        ELSE '100+点赞'
    END as likes_range,
    COUNT(*) as count
FROM douyin_aweme_comment
WHERE like_count IS NOT NULL
GROUP BY likes_range
```

**分布区间**:
- 0点赞: 无点赞评论
- 1-4点赞: 低点赞评论
- 5-19点赞: 中等点赞评论
- 20-99点赞: 高点赞评论
- 100+点赞: 超高点赞评论

#### 5.1.5 子评论数分布
**SQL查询**:
```sql
SELECT 
    CASE 
        WHEN CAST(sub_comment_count AS UNSIGNED) = 0 THEN '0子评论'
        WHEN CAST(sub_comment_count AS UNSIGNED) < 3 THEN '1-2子评论'
        WHEN CAST(sub_comment_count AS UNSIGNED) < 10 THEN '3-9子评论'
        WHEN CAST(sub_comment_count AS UNSIGNED) < 50 THEN '10-49子评论'
        ELSE '50+子评论'
    END as sub_comments_range,
    COUNT(*) as count
FROM douyin_aweme_comment
WHERE sub_comment_count IS NOT NULL
GROUP BY sub_comments_range
```

**分布区间**:
- 0子评论: 无回复评论
- 1-2子评论: 低回复评论
- 3-9子评论: 中等回复评论
- 10-49子评论: 高回复评论
- 50+子评论: 超高回复评论

### 5.2 过滤效果分析

#### 算法：`analyze_filtering_effect(conn, df_original, df_filtered)`
**目的**: 分析各过滤规则的效果和贡献度

#### 5.2.1 总体过滤效果
**统计指标**:
- 数据库原始数据量
- SQL过滤后数据量
- 垃圾评论过滤后数据量
- 各阶段过滤数量
- 总过滤率

#### 5.2.2 各过滤条件效果分析
**分析维度**:
1. 内容长度过滤效果
2. 特殊字符过滤效果
3. 广告关键词过滤效果
4. 重复字符过滤效果
5. 用户签名过滤效果

**计算方法**:
```python
# 以内容长度过滤为例
short_content = len(df_db_original[df_db_original['content'].str.len() < 5])
short_percentage = (short_content / total_db_original) * 100
```

#### 5.2.3 数据质量提升统计
**统计指标**:
- 平均内容长度变化
- 特殊字符比例变化
- 数据质量提升程度

## 六、数据输出格式

### 6.1 保存字段说明
**输出字段**:
```python
save_columns = [
    'comment_id',        # 评论ID
    'aweme_id',          # 视频ID
    'parent_comment_id', # 父评论ID
    'content',           # 原始内容
    'content_cleaned',   # 清洗后内容
    'content_segmented', # 分词结果
    'create_time',       # 原始时间戳
    'create_time_dt',    # 时间对象
    'create_time_str',   # 格式化时间字符串
    'like_count',        # 点赞数
    'sub_comment_count', # 子评论数
    'word_count'         # 分词数量
]
```

### 6.2 输出格式
**文件格式**: JSON
**编码**: UTF-8
**结构**: 记录数组格式

**示例输出**:
```json
[
  {
    "comment_id": "123456789",
    "aweme_id": "987654321",
    "parent_comment_id": "0",
    "content": "这个视频真不错！👍",
    "content_cleaned": "这个视频真不错！",
    "content_segmented": ["视频", "不错"],
    "create_time": 1640995200,
    "create_time_dt": "2022-01-01T00:00:00",
    "create_time_str": "2022-01-01 00:00:00",
    "like_count": 5,
    "sub_comment_count": 2,
    "word_count": 2
  }
]
```

## 七、重要更新说明

### 7.1 模块职责分离
**更新内容**: 数据准备和清洗模块不再负责时间差计算
- ❌ 移除了 `calculate_time_diff()` 函数
- ❌ 移除了时间差统计输出
- ❌ 移除了保存字段中的时间差字段

**原因**: 实现模块职责分离，时间差计算由专门的时间分析模块负责

### 7.2 数据流程优化
**新的数据流程**:
```
原始数据 → 数据准备和清洗 → 清洗后数据 → 时间分析模块 → 时间差计算 → 可视化报告
```

**优势**:
- 模块职责更清晰
- 代码复用性更好
- 维护性更强
- 扩展性更好

## 八、算法优化建议

### 8.1 性能优化
1. **批量处理**: 使用pandas的向量化操作替代循环
2. **数据库优化**: 添加适当的索引提高查询速度
3. **内存管理**: 分批处理大数据集

### 8.2 准确性优化
1. **规则调优**: 根据实际数据分布调整过滤阈值
2. **关键词更新**: 定期更新广告关键词库
3. **停用词优化**: 根据领域特点调整停用词列表

### 8.3 可扩展性优化
1. **模块化设计**: 将各阶段算法独立为可配置模块
2. **参数化配置**: 支持外部配置文件调整算法参数
3. **多平台支持**: 扩展支持其他社交媒体平台

## 九、总结

本文档详细说明了抖音评论数据清洗的完整算法体系，包括：

1. **数据准备阶段**: 原始数据提取，保持数据完整性
2. **数据过滤阶段**: 多维度垃圾评论识别和过滤
3. **数据清洗阶段**: 文本标准化和预处理
4. **数据分析阶段**: 分布特征分析和过滤效果评估

**重要更新**: 模块职责分离，时间差计算功能已移至专门的时间分析模块，提高了代码的模块化和可维护性。

每个算法都经过精心设计，既保证了数据质量，又避免了过度过滤。通过详细的示例说明，使得算法规则更加清晰易懂，便于后续的维护和优化。 