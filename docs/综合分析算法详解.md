# ç»¼åˆåˆ†æç®—æ³•è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

ç»¼åˆåˆ†ææ¨¡å—æ˜¯æ–‡æœ¬åˆ†æç³»ç»Ÿçš„ç»Ÿä¸€å…¥å£ç‚¹ï¼Œé›†æˆäº†æ‰€æœ‰ä»ä¼—å¿ƒç†åˆ†ææ¨¡å—ï¼Œæä¾›ä¸€é”®å¼çš„å®Œæ•´ä»ä¼—å¿ƒç†åˆ†æåŠŸèƒ½ã€‚è¯¥æ¨¡å—é€šè¿‡å¤šç»´åº¦åˆ†æ•°èšåˆï¼Œç”Ÿæˆç»¼åˆä»ä¼—å¿ƒç†è¯„ä¼°æŠ¥å‘Šã€‚

## ğŸ—ï¸ æ¨¡å—æ¶æ„

### æ ¸å¿ƒæ–‡ä»¶
- **ä¸»æ¨¡å—**: `text_analysis_unified.py`
- **ä¾èµ–æ¨¡å—**: 
  - `conformity_time_analyzer.py` - æ—¶é—´ä»ä¼—å¿ƒç†åˆ†æ
  - `sentiment_conformity_analyzer.py` - æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ
  - `similarity_conformity_analyzer.py` - ç›¸ä¼¼åº¦ä»ä¼—å¿ƒç†åˆ†æ
  - `like_conformity_analyzer.py` - ç‚¹èµä»ä¼—å¿ƒç†åˆ†æ

### æ¨¡å—å…³ç³»å›¾
```
text_analysis_unified.py
â”œâ”€â”€ ConformityTimeAnalyzer
â”œâ”€â”€ SentimentConformityAnalyzer
â”œâ”€â”€ SimilarityConformityAnalyzer
â””â”€â”€ LikeConformityAnalyzer
    â†“
generate_comprehensive_result()
    â†“
comprehensive_conformity_analysis.json
```

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### 1. ç»Ÿä¸€å…¥å£ç‚¹
- **åŠŸèƒ½**: æä¾›ç»Ÿä¸€çš„å‘½ä»¤è¡Œæ¥å£
- **æ”¯æŒå‘½ä»¤**: 
  - `conformity` - ç»¼åˆåˆ†æ
  - `time` - æ—¶é—´åˆ†æ
  - `sentiment` - æƒ…æ„Ÿåˆ†æ
  - `similarity` - ç›¸ä¼¼åº¦åˆ†æ
  - `like` - ç‚¹èµåˆ†æ
  - `cleaning` - æ•°æ®æ¸…æ´—

### 2. ç»¼åˆåˆ†ææµç¨‹
```python
def run_conformity_analysis(args):
    """è¿è¡Œä»ä¼—å¿ƒç†ç»¼åˆåˆ†æ"""
    # 1. åŠ è½½æ•°æ®
    data = load_data(args)
    
    # 2. è¿è¡Œå„ä¸ªåˆ†ææ¨¡å—
    time_result = run_time_analysis(data)
    sentiment_result = run_sentiment_analysis(data)
    similarity_result = run_similarity_analysis(data)
    like_result = run_like_analysis(data)
    
    # 3. ç”Ÿæˆç»¼åˆç»“æœ
    comprehensive_result = generate_comprehensive_result(
        [time_result, sentiment_result, similarity_result, like_result], 
        data
    )
    
    # 4. ä¿å­˜ç»“æœå’Œç”ŸæˆæŠ¥å‘Š
    save_results(comprehensive_result)
    generate_report(comprehensive_result)
```

### 3. å¤šç»´åº¦åˆ†æ•°èšåˆ
```python
def generate_comprehensive_result(results, data):
    """ç”Ÿæˆç»¼åˆåˆ†æç»“æœ"""
    # æå–å„ç»´åº¦åˆ†æ•°
    time_score = extract_score(time_result, 'parent_conformity_score')
    sentiment_score = extract_score(sentiment_result, 'parent_sentiment_conformity_score')
    similarity_score = extract_score(similarity_result, 'parent_similarity_conformity_score')
    like_score = extract_score(like_result, 'parent_like_conformity_score')
    
    # è®¡ç®—ç»¼åˆåˆ†æ•°
    conformity_scores = [time_score, sentiment_score, similarity_score, like_score]
    overall_conformity_score = np.mean(conformity_scores)
    
    # ç”Ÿæˆç»“æœç»“æ„
    return {
        "analysis_metadata": {...},
        "comprehensive_conformity_analysis": {
            "overall_conformity_score": overall_conformity_score,
            "conformity_level": get_conformity_level(overall_conformity_score),
            "score_breakdown": {...},
            "analysis_summary": {...}
        },
        "detailed_results": {...}
    }
```

## ğŸ“Š ç®—æ³•åŸç†

### 1. åˆ†æ•°èšåˆç®—æ³•
- **æ–¹æ³•**: ç®—æœ¯å¹³å‡
- **å…¬å¼**: `overall_score = (time_score + sentiment_score + similarity_score + like_score) / 4`
- **æƒé‡**: å„ç»´åº¦ç­‰æƒé‡
- **èŒƒå›´**: [0, 1]

### 2. ä»ä¼—å¿ƒç†ç­‰çº§åˆ†ç±»
```python
def get_conformity_level(score):
    """æ ¹æ®åˆ†æ•°ç¡®å®šä»ä¼—å¿ƒç†ç­‰çº§"""
    if score >= 0.8:
        return "æé«˜ä»ä¼—å¿ƒç†"
    elif score >= 0.6:
        return "é«˜ä»ä¼—å¿ƒç†"
    elif score >= 0.4:
        return "ä¸­ç­‰ä»ä¼—å¿ƒç†"
    elif score >= 0.2:
        return "ä½ä»ä¼—å¿ƒç†"
    else:
        return "æä½ä»ä¼—å¿ƒç†"
```

### 3. ç»“æœç»“æ„è®¾è®¡
```json
{
  "analysis_metadata": {
    "analysis_time": "2025-09-07 18:15:17",
    "analyzer_version": "v1.0.0",
    "analysis_type": "comprehensive_conformity_analysis",
    "total_comments": 337,
    "parent_comment_id": "7306470754056569635"
  },
  "comprehensive_conformity_analysis": {
    "overall_conformity_score": 0.3903,
    "conformity_level": "ä½ä»ä¼—å¿ƒç†",
    "score_breakdown": {
      "time_conformity_score": 0.2358,
      "sentiment_conformity_score": 0.7501,
      "similarity_conformity_score": 0.5719,
      "like_conformity_score": 0.0034
    },
    "analysis_summary": {
      "time_conformity": {"score": 0.2358, "description": "æ—¶é—´ç»´åº¦ä»ä¼—å¿ƒç†åˆ†æ"},
      "sentiment_conformity": {"score": 0.7501, "description": "æƒ…æ„Ÿç»´åº¦ä»ä¼—å¿ƒç†åˆ†æ"},
      "similarity_conformity": {"score": 0.5719, "description": "æ–‡æœ¬ç›¸ä¼¼åº¦ä»ä¼—å¿ƒç†åˆ†æ"},
      "like_conformity": {"score": 0.0034, "description": "ç‚¹èµè¡Œä¸ºä»ä¼—å¿ƒç†åˆ†æ"}
    }
  },
  "detailed_results": {
    "time_conformity_analysis": {...},
    "sentiment_conformity_analysis": {...},
    "similarity_conformity_analysis": {...},
    "like_conformity_analysis": {...}
  }
}
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. å‘½ä»¤è¡Œä½¿ç”¨

#### ç»¼åˆåˆ†æï¼ˆæ¨èï¼‰
```bash
# åŸºæœ¬ç”¨æ³•
python text_analysis_unified.py conformity --use-cleaned-data --video-id 7306437681045654834

# æµ‹è¯•æ¨¡å¼
python text_analysis_unified.py conformity --use-cleaned-data --test

# ä¸ä¿å­˜ç»“æœæ–‡ä»¶
python text_analysis_unified.py conformity --use-cleaned-data --no-save

# ä¸ç”ŸæˆæŠ¥å‘Š
python text_analysis_unified.py conformity --use-cleaned-data --no-report
```

#### å•ç‹¬æ¨¡å—åˆ†æ
```bash
# æ—¶é—´ä»ä¼—å¿ƒç†åˆ†æ
python text_analysis_unified.py time --use-cleaned-data --video-id 7306437681045654834

# æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æ
python text_analysis_unified.py sentiment --use-cleaned-data --video-id 7306437681045654834

# ç›¸ä¼¼åº¦ä»ä¼—å¿ƒç†åˆ†æ
python text_analysis_unified.py similarity --use-cleaned-data --video-id 7306437681045654834

# ç‚¹èµä»ä¼—å¿ƒç†åˆ†æ
python text_analysis_unified.py like --use-cleaned-data --video-id 7306437681045654834
```

### 2. å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|------|--------|
| `--use-cleaned-data` | flag | ä½¿ç”¨æ¸…æ´—åçš„æ•°æ® | False |
| `--video-id` | str | è§†é¢‘ID | None |
| `--limit` | int | é™åˆ¶åˆ†ææ•°é‡ | None |
| `--cleaned-data-path` | str | æ¸…æ´—æ•°æ®æ–‡ä»¶è·¯å¾„ | None |
| `--test` | flag | æµ‹è¯•æ¨¡å¼ï¼Œåªåˆ†æå°‘é‡æ•°æ® | False |
| `--no-save` | flag | ä¸ä¿å­˜ç»“æœæ–‡ä»¶ | False |
| `--no-report` | flag | ä¸ç”Ÿæˆåˆ†ææŠ¥å‘Š | False |
| `--no-viz` | flag | ä¸åˆ›å»ºå¯è§†åŒ–å›¾è¡¨ | False |

### 3. ç¨‹åºåŒ–ä½¿ç”¨
```python
from text_analysis_unified import run_conformity_analysis
import argparse

# åˆ›å»ºå‚æ•°å¯¹è±¡
args = argparse.Namespace()
args.use_cleaned_data = True
args.video_id = "7306437681045654834"
args.test = False
args.no_save = False
args.no_report = False

# è¿è¡Œç»¼åˆåˆ†æ
run_conformity_analysis(args)
```

## ğŸ“ˆ è¾“å‡ºç»“æœ

### 1. æ§åˆ¶å°è¾“å‡º
```
============================================================
ğŸ“Š ä»ä¼—å¿ƒç†ç»¼åˆåˆ†ææŠ¥å‘Š
============================================================
ğŸ“… åˆ†ææ—¶é—´: 2025-09-07 18:15:17
ğŸ“ çˆ¶è¯„è®ºID: 7306470754056569635
ğŸ’¬ çˆ¶è¯„è®ºå†…å®¹: 261ï¼Œæˆ‘çš„ï¼seeyæ˜¯æˆ‘å‘çš„ï¼ï¼ï¼
ğŸ“Š æ€»è¯„è®ºæ•°: 337

----------------------------------------
ğŸ¯ ç»¼åˆä»ä¼—å¿ƒç†åˆ†æç»“æœ
----------------------------------------
ğŸ† ç»¼åˆä»ä¼—å¿ƒç†åˆ†æ•°: 0.3903
ğŸ“ˆ ä»ä¼—å¿ƒç†ç­‰çº§: ä½ä»ä¼—å¿ƒç†

ğŸ“Š å„ç»´åº¦ä»ä¼—å¿ƒç†åˆ†æ•°:
  â° æ—¶é—´ä»ä¼—å¿ƒç†: 0.2358
  ğŸ˜Š æƒ…æ„Ÿä»ä¼—å¿ƒç†: 0.7501
  ğŸ“ ç›¸ä¼¼åº¦ä»ä¼—å¿ƒç†: 0.5719
  ğŸ‘ ç‚¹èµä»ä¼—å¿ƒç†: 0.0034

ğŸ’¡ åˆ†æå»ºè®®:
  ğŸ¯ è¯¥çˆ¶è¯„è®ºç¯å¢ƒä»ä¼—å¿ƒç†ç‰¹å¾ä¸æ˜æ˜¾
  ğŸ“Š å»ºè®®å…³æ³¨å…¶ä»–ç¤¾äº¤è¡Œä¸ºç‰¹å¾
============================================================
```

### 2. JSONç»“æœæ–‡ä»¶
- **æ–‡ä»¶å**: `comprehensive_conformity_analysis_YYYYMMDD_HHMMSS.json`
- **ä½ç½®**: `data/`
- **å†…å®¹**: å®Œæ•´çš„åˆ†æç»“æœï¼ŒåŒ…å«æ‰€æœ‰ç»´åº¦çš„è¯¦ç»†æ•°æ®

## ğŸ” æŠ€æœ¯ç‰¹ç‚¹

### 1. é”™è¯¯å¤„ç†
- **JSONåºåˆ—åŒ–**: è‡ªåŠ¨å¤„ç†NumPyç±»å‹è½¬æ¢
- **APIè°ƒç”¨**: å®Œå–„çš„è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
- **æ•°æ®éªŒè¯**: è¾“å…¥æ•°æ®æ ¼å¼æ£€æŸ¥

### 2. æ€§èƒ½ä¼˜åŒ–
- **å¹¶å‘å¤„ç†**: æ”¯æŒå¤šæ¨¡å—å¹¶è¡Œåˆ†æ
- **ç¼“å­˜æœºåˆ¶**: é¿å…é‡å¤APIè°ƒç”¨
- **å†…å­˜ç®¡ç†**: å¤§æ•°æ®é›†åˆ†å—å¤„ç†

### 3. ç”¨æˆ·ä½“éªŒ
- **è¿›åº¦æ˜¾ç¤º**: å®æ—¶æ˜¾ç¤ºåˆ†æè¿›åº¦
- **è¯¦ç»†æ—¥å¿—**: å®Œæ•´çš„æ‰§è¡Œæ—¥å¿—
- **çµæ´»é…ç½®**: æ”¯æŒå¤šç§å‚æ•°ç»„åˆ

## ğŸ“Š å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1: æŠ–éŸ³è¯„è®ºä»ä¼—å¿ƒç†åˆ†æ
- **æ•°æ®è§„æ¨¡**: 337æ¡è¯„è®º
- **åˆ†æç»“æœ**: ç»¼åˆåˆ†æ•°0.3903ï¼ˆä½ä»ä¼—å¿ƒç†ï¼‰
- **ä¸»è¦å‘ç°**:
  - æƒ…æ„Ÿä»ä¼—å¿ƒç†æœ€é«˜ï¼ˆ0.7501ï¼‰
  - ç‚¹èµä»ä¼—å¿ƒç†æœ€ä½ï¼ˆ0.0034ï¼‰
  - ç”¨æˆ·ä¿æŒç›¸å¯¹ç‹¬ç«‹çš„æ€è€ƒ

### æ¡ˆä¾‹2: ç¤¾äº¤åª’ä½“è¡Œä¸ºç ”ç©¶
- **åº”ç”¨åœºæ™¯**: ç ”ç©¶ç”¨æˆ·åœ¨ä¸åŒç»´åº¦ä¸Šçš„ä»ä¼—è¡Œä¸º
- **åˆ†æä»·å€¼**: ä¸ºç¤¾äº¤åª’ä½“è¿è¥æä¾›æ•°æ®æ”¯æŒ
- **ç ”ç©¶æ„ä¹‰**: ç†è§£ç”¨æˆ·è¡Œä¸ºæ¨¡å¼å’Œç¤¾äº¤å¿ƒç†

## ğŸ”„ é›†æˆå·¥ä½œæµ

### å®Œæ•´å·¥ä½œæµç¨‹
```
åŸå§‹æ•°æ® â†’ æ•°æ®æ¸…æ´—æ¨¡å— â†’ ç»¼åˆåˆ†ææ¨¡å— â†’ ç»“æœè¾“å‡º
    â†“           â†“              â†“           â†“
  351æ¡è¯„è®º   æ—¶é—´æ ‡å‡†åŒ–å¤„ç†   å¤šç»´åº¦åˆ†æ   ç»¼åˆæŠ¥å‘Š
    â†“           â†“              â†“           â†“
  åƒåœ¾è¿‡æ»¤   çˆ¶å­è¯„è®ºè¯†åˆ«     åˆ†æ•°èšåˆ     JSONæ–‡ä»¶
    â†“           â†“              â†“           â†“
  æ–‡æœ¬æ¸…æ´—   æ—¶é—´å·®è®¡ç®—       ç­‰çº§è¯„ä¼°     æ§åˆ¶å°æŠ¥å‘Š
    â†“           â†“              â†“           â†“
  åˆ†è¯å¤„ç†   ä¿å­˜æ ‡å‡†åŒ–æ•°æ®   è¯¦ç»†åˆ†æ     å¯è§†åŒ–å›¾è¡¨
```

### æ¨èä½¿ç”¨æµç¨‹
```bash
# 1. æ•°æ®æ¸…æ´—ï¼ˆåŒ…å«æ—¶é—´æ ‡å‡†åŒ–ï¼‰
python text_analysis_unified.py cleaning --video-id 7306437681045654834

# 2. ç»¼åˆåˆ†æï¼ˆä½¿ç”¨æ¸…æ´—åçš„æ•°æ®ï¼‰
python text_analysis_unified.py conformity --use-cleaned-data --video-id 7306437681045654834
```

### æ•°æ®æ ¼å¼è¦æ±‚
æ¸…æ´—åçš„æ•°æ®åŒ…å«ä»¥ä¸‹å…³é”®å­—æ®µï¼š
- `comment_time`: æ ‡å‡†åŒ–çš„æ—¶é—´å­—æ®µ
- `is_parent`: çˆ¶è¯„è®ºæ ‡è¯†
- `time_diff_seconds`: ä¸çˆ¶è¯„è®ºçš„æ—¶é—´å·®
- `words`: åˆ†è¯ç»“æœ
- `word_count`: è¯æ•°ç»Ÿè®¡

### é›†æˆæ•ˆæœéªŒè¯
| æŒ‡æ ‡ | åŸå§‹æ•°æ® | æ¸…æ´—åæ•°æ® | åˆ†æç»“æœ |
|------|----------|------------|----------|
| æ€»è¯„è®ºæ•° | 351 | 330 | 337 |
| çˆ¶è¯„è®ºæ•° | 1 | 1 | 1 |
| å­è¯„è®ºæ•° | 350 | 329 | 336 |
| åƒåœ¾è¯„è®º | 8 | 0 | 0 |
| ç»¼åˆä»ä¼—å¿ƒç†åˆ†æ•° | - | - | 0.3903 |

## ğŸ› ï¸ æ‰©å±•å¼€å‘

### 1. æ·»åŠ æ–°çš„åˆ†æç»´åº¦
```python
# 1. åˆ›å»ºæ–°çš„åˆ†æå™¨ç±»
class NewConformityAnalyzer(BaseAnalyzer):
    def analyze(self, data):
        # å®ç°åˆ†æé€»è¾‘
        return result

# 2. åœ¨run_conformity_analysisä¸­æ·»åŠ è°ƒç”¨
new_result = run_new_analysis(data)

# 3. åœ¨generate_comprehensive_resultä¸­èšåˆåˆ†æ•°
new_score = extract_score(new_result, 'new_conformity_score')
conformity_scores.append(new_score)
```

### 2. è‡ªå®šä¹‰æƒé‡èšåˆ
```python
def generate_comprehensive_result_weighted(results, weights):
    """ä½¿ç”¨è‡ªå®šä¹‰æƒé‡çš„ç»¼åˆåˆ†æ"""
    weighted_scores = []
    for result, weight in zip(results, weights):
        score = extract_score(result)
        weighted_scores.append(score * weight)
    
    overall_score = sum(weighted_scores) / sum(weights)
    return overall_score
```

### 3. ç»“æœå¯è§†åŒ–
```python
def generate_visualization(comprehensive_result):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    scores = comprehensive_result['score_breakdown']
    
    # é›·è¾¾å›¾
    create_radar_chart(scores)
    
    # æŸ±çŠ¶å›¾
    create_bar_chart(scores)
    
    # è¶‹åŠ¿å›¾
    create_trend_chart(scores)
```

## ğŸ“ ç‰ˆæœ¬å†å²

### v5.0.0 (2025-09-07)
- âœ… **ç»¼åˆåˆ†æåŠŸèƒ½**: æ–°å¢ç»Ÿä¸€å…¥å£ç‚¹ï¼Œæ”¯æŒä¸€é”®è¿è¡Œå®Œæ•´çš„ä»ä¼—å¿ƒç†ç»¼åˆåˆ†æ
- âœ… **JSONåºåˆ—åŒ–ä¼˜åŒ–**: ä¿®å¤NumPyç±»å‹åºåˆ—åŒ–é—®é¢˜ï¼Œç¡®ä¿ç»“æœæ–‡ä»¶æ­£ç¡®ä¿å­˜
- âœ… **é”™è¯¯å¤„ç†å®Œå–„**: å¢å¼ºé”™è¯¯å¤„ç†å’Œç±»å‹è½¬æ¢æœºåˆ¶
- âœ… **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**: æ”¹è¿›å‘½ä»¤è¡Œç•Œé¢å’Œè¿›åº¦æ˜¾ç¤º

### v4.0.0 (2025-09-07)
- âœ… **æ¨¡å—é›†æˆ**: é›†æˆæ‰€æœ‰ä»ä¼—å¿ƒç†åˆ†ææ¨¡å—
- âœ… **ç»“æœèšåˆ**: å®ç°å¤šç»´åº¦åˆ†æ•°èšåˆç®—æ³•
- âœ… **æŠ¥å‘Šç”Ÿæˆ**: è‡ªåŠ¨ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [ä»ä¼—å¿ƒç†æ—¶é—´åˆ†æç®—æ³•è¯¦è§£.md](./ä»ä¼—å¿ƒç†æ—¶é—´åˆ†æç®—æ³•è¯¦è§£.md)
- [æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æç®—æ³•è¯¦è§£.md](./æƒ…æ„Ÿä»ä¼—å¿ƒç†åˆ†æç®—æ³•è¯¦è§£.md)
- [ç›¸ä¼¼åº¦ä»ä¼—å¿ƒç†åˆ†æç®—æ³•è¯¦è§£.md](./ç›¸ä¼¼åº¦ä»ä¼—å¿ƒç†åˆ†æç®—æ³•è¯¦è§£.md)
- [ç‚¹èµä»ä¼—å¿ƒç†åˆ†æç®—æ³•è¯¦è§£.md](./ç‚¹èµä»ä¼—å¿ƒç†åˆ†æç®—æ³•è¯¦è§£.md)
- [æ•°æ®æ¸…æ´—ç®—æ³•è¯¦è§£.md](./æ•°æ®æ¸…æ´—ç®—æ³•è¯¦è§£.md)

---

*ç»¼åˆåˆ†æç®—æ³•è¯¦è§£ v5.0.0 - 2025-09-07*
