# é˜¿é‡Œäº‘APIè°ƒç”¨ç®—æ³•è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è§£é‡Šäº†MediaCrawleré¡¹ç›®ä¸­é˜¿é‡Œäº‘NLPæƒ…æ„Ÿåˆ†æAPIçš„è°ƒç”¨ç®—æ³•å®ç°ï¼ŒåŒ…æ‹¬SDKè°ƒç”¨ã€HTTPè¯·æ±‚ã€ç­¾åéªŒè¯ã€å¹¶å‘å¤„ç†ç­‰æ ¸å¿ƒæœºåˆ¶ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

```
AliyunAnalyzer
â”œâ”€â”€ SDKè°ƒç”¨æ–¹å¼ (_analyze_with_sdk)
â”œâ”€â”€ HTTPè°ƒç”¨æ–¹å¼ (_analyze_with_http)
â”œâ”€â”€ ç­¾åç”Ÿæˆ (_generate_signature)
â”œâ”€â”€ å“åº”è§£æ (_parse_response)
â””â”€â”€ é”™è¯¯å¤„ç†æœºåˆ¶
```

### è°ƒç”¨æµç¨‹

```mermaid
graph TD
    A[æ–‡æœ¬è¾“å…¥] --> B{é€‰æ‹©è°ƒç”¨æ–¹å¼}
    B -->|ä¼˜å…ˆ| C[SDKè°ƒç”¨]
    B -->|å¤‡é€‰| D[HTTPè°ƒç”¨]
    C --> E{SDKæˆåŠŸ?}
    D --> F{HTTPæˆåŠŸ?}
    E -->|æ˜¯| G[è§£æå“åº”]
    E -->|å¦| D
    F -->|æ˜¯| G
    F -->|å¦| H[è¿”å›é»˜è®¤ç»“æœ]
    G --> I[è¿”å›æƒ…æ„Ÿåˆ†æç»“æœ]
    H --> I
```

## ğŸ”§ æ ¸å¿ƒç®—æ³•å®ç°

### 1. åˆå§‹åŒ–é…ç½®

```python
class AliyunAnalyzer:
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
        self.access_key_id = os.getenv('NLP_AK_ENV')
        self.access_key_secret = os.getenv('NLP_SK_ENV')
        self.region_id = os.getenv('NLP_REGION_ENV', 'cn-hangzhou')
        self.endpoint = f"https://nlp.{self.region_id}.aliyuncs.com"
        
        # éªŒè¯é…ç½®
        if not self.access_key_id or not self.access_key_secret:
            raise ValueError("é˜¿é‡Œäº‘AccessKeyæœªé…ç½®")
```

**ç®—æ³•è¦ç‚¹ï¼š**
- ä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†æ•æ„Ÿä¿¡æ¯
- æ”¯æŒå¤šåŒºåŸŸé…ç½®
- å¯åŠ¨æ—¶éªŒè¯é…ç½®å®Œæ•´æ€§

### 2. åŒé‡è°ƒç”¨ç­–ç•¥

```python
def analyze_text(self, text: str) -> Dict[str, Union[str, float]]:
    try:
        # ä¼˜å…ˆä½¿ç”¨SDK
        return self._analyze_with_sdk(text)
    except Exception as e:
        logger.warning(f"SDKåˆ†æå¤±è´¥ï¼Œå°è¯•HTTPè¯·æ±‚: {e}")
        try:
            return self._analyze_with_http(text)
        except Exception as e2:
            logger.error(f"HTTPè¯·æ±‚ä¹Ÿå¤±è´¥: {e2}")
            # è¿”å›é»˜è®¤ç»“æœ
            return {
                'sentiment': 'neutral',
                'score': 0.0,
                'confidence': 0.0,
                'error': f"APIè¿æ¥å¤±è´¥: {e2}",
                'method': 'aliyun'
            }
```

**ç®—æ³•è¦ç‚¹ï¼š**
- **å®¹é”™æœºåˆ¶**ï¼šSDKå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°HTTP
- **ä¼˜é›…é™çº§**ï¼šåŒé‡å¤±è´¥æ—¶è¿”å›é»˜è®¤ç»“æœ
- **é”™è¯¯è¿½è¸ª**ï¼šè®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯

### 3. SDKè°ƒç”¨å®ç°

```python
def _analyze_with_sdk(self, text: str) -> Dict[str, Union[str, float]]:
    try:
        from aliyunsdkcore.client import AcsClient
        from aliyunsdkcore.request import CommonRequest
        
        # åˆ›å»ºAcsClientå®ä¾‹
        client = AcsClient(
            self.access_key_id,
            self.access_key_secret,
            self.region_id
        )
        
        # æ„å»ºè¯·æ±‚
        request = CommonRequest()
        request.set_domain('alinlp.cn-hangzhou.aliyuncs.com')
        request.set_version('2020-06-29')
        request.set_action_name('GetSaChGeneral')
        request.add_query_param('ServiceCode', 'alinlp')
        request.add_query_param('Text', text)
        
        # å‘é€è¯·æ±‚
        response = client.do_action_with_exception(request)
        result = json.loads(response)
        
        return self._parse_response(result)
        
    except ImportError:
        raise Exception("é˜¿é‡Œäº‘SDKæœªå®‰è£…")
    except Exception as e:
        raise e
```

**ç®—æ³•è¦ç‚¹ï¼š**
- **SDKä¼˜å…ˆ**ï¼šä½¿ç”¨å®˜æ–¹SDKç¡®ä¿ç¨³å®šæ€§
- **å‚æ•°é…ç½®**ï¼šæ­£ç¡®è®¾ç½®APIç‰ˆæœ¬å’ŒåŸŸå
- **å¼‚å¸¸å¤„ç†**ï¼šåŒºåˆ†SDKç¼ºå¤±å’ŒAPIè°ƒç”¨é”™è¯¯

### 4. HTTPè°ƒç”¨å®ç°

```python
def _analyze_with_http(self, text: str) -> Dict[str, Union[str, float]]:
    import requests
    import hashlib
    import hmac
    import base64
    
    # æ„å»ºè¯·æ±‚å‚æ•°
    params = {
        'Action': 'SentimentAnalysis',
        'Version': '2018-04-08',
        'Format': 'JSON',
        'Timestamp': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
        'SignatureMethod': 'HMAC-SHA1',
        'SignatureVersion': '1.0',
        'SignatureNonce': str(int(time.time() * 1000)),
        'AccessKeyId': self.access_key_id,
        'Text': text,
    }
    
    # ç”Ÿæˆç­¾å
    signature = self._generate_signature('POST', '/', params)
    params['Signature'] = signature
    
    # å‘é€è¯·æ±‚
    response = requests.post(self.endpoint, data=params, timeout=30)
    response.raise_for_status()
    result = response.json()
    return self._parse_response(result)
```

**ç®—æ³•è¦ç‚¹ï¼š**
- **æ‰‹åŠ¨ç­¾å**ï¼šå®ç°é˜¿é‡Œäº‘APIç­¾åç®—æ³•
- **å‚æ•°æ ‡å‡†åŒ–**ï¼šæŒ‰é˜¿é‡Œäº‘è§„èŒƒæ„å»ºè¯·æ±‚
- **è¶…æ—¶æ§åˆ¶**ï¼šè®¾ç½®30ç§’è¶…æ—¶é¿å…é˜»å¡

### 5. ç­¾åç”Ÿæˆç®—æ³•

```python
def _generate_signature(self, method: str, path: str, params: Dict) -> str:
    # 1. å‚æ•°æ’åºå’Œæ‹¼æ¥
    canonicalized_query_string = "&".join([f"{k}={v}" for k, v in sorted(params.items())])
    
    # 2. æ„å»ºç­¾åå­—ç¬¦ä¸²
    string_to_sign = f"{method}\n{path}\n{canonicalized_query_string}\n"
    
    # 3. HMAC-SHA1ç­¾å
    signature = hmac.new(
        self.access_key_secret.encode('utf-8'),
        string_to_sign.encode('utf-8'),
        hashlib.sha1
    ).digest()
    
    # 4. Base64ç¼–ç 
    return base64.b64encode(signature).decode('utf-8')
```

**ç®—æ³•è¦ç‚¹ï¼š**
- **å‚æ•°æ’åº**ï¼šæŒ‰å­—å…¸åºæ’åºç¡®ä¿ä¸€è‡´æ€§
- **å­—ç¬¦ä¸²æ‹¼æ¥**ï¼šæŒ‰é˜¿é‡Œäº‘è§„èŒƒæ„å»ºç­¾åå­—ç¬¦ä¸²
- **HMAC-SHA1**ï¼šä½¿ç”¨æ ‡å‡†åŠ å¯†ç®—æ³•
- **Base64ç¼–ç **ï¼šæœ€ç»ˆç­¾åæ ¼å¼

### 6. å“åº”è§£æç®—æ³•

```python
def _parse_response(self, result: Dict) -> Dict[str, Union[str, float]]:
    try:
        # è§£æDataå­—æ®µ
        data_str = result.get('Data', '{}')
        if isinstance(data_str, str):
            data = json.loads(data_str)
        else:
            data = data_str
        
        # è·å–ç»“æœ
        result_data = data.get('result', {})
        sentiment_zh = result_data.get('sentiment', '')
        positive_prob = float(result_data.get('positive_prob', 0))
        negative_prob = float(result_data.get('negative_prob', 0))
        neutral_prob = float(result_data.get('neutral_prob', 0))
        
        # æƒ…æ„Ÿæ˜ å°„
        sentiment_map = {
            'positive': 'positive', 'negative': 'negative', 'neutral': 'neutral',
            'æ­£å‘': 'positive', 'è´Ÿå‘': 'negative', 'ä¸­æ€§': 'neutral',
            'æ­£é¢': 'positive', 'è´Ÿé¢': 'negative',
        }
        
        sentiment = sentiment_map.get(sentiment_zh.lower(), 'neutral')
        
        # è®¡ç®—åˆ†æ•°å’Œç½®ä¿¡åº¦
        if sentiment == 'positive':
            score = positive_prob
            confidence = positive_prob
        elif sentiment == 'negative':
            score = -negative_prob
            confidence = negative_prob
        else:
            score = 0.0
            confidence = neutral_prob
        
        return {
            'sentiment': sentiment,
            'score': score,
            'confidence': confidence,
            'positive_prob': positive_prob,
            'negative_prob': negative_prob,
            'neutral_prob': neutral_prob,
            'method': 'aliyun'
        }
    except Exception as e:
        raise e
```

**ç®—æ³•è¦ç‚¹ï¼š**
- **æ•°æ®è§£æ**ï¼šå¤„ç†åµŒå¥—çš„JSONç»“æ„
- **æ¦‚ç‡æ˜ å°„**ï¼šå°†ä¸­æ–‡æƒ…æ„Ÿæ ‡ç­¾æ˜ å°„ä¸ºè‹±æ–‡
- **åˆ†æ•°è®¡ç®—**ï¼šæ ¹æ®æƒ…æ„Ÿç±»å‹è®¡ç®—æ ‡å‡†åŒ–åˆ†æ•°
- **ç½®ä¿¡åº¦è¯„ä¼°**ï¼šä½¿ç”¨æ¦‚ç‡å€¼ä½œä¸ºç½®ä¿¡åº¦

## âš¡ å¹¶å‘å¤„ç†ç®—æ³•

### 1. å¹¶å‘æ¶æ„

```python
def _analyze_texts_concurrent(self, texts: List[str]) -> List[Dict[str, Union[str, float]]]:
    from concurrent.futures import ThreadPoolExecutor, as_completed
    
    # 1. æ–‡æœ¬å»é‡
    unique_index: Dict[str, int] = {}
    order_to_text: Dict[int, str] = {}
    for i, t in enumerate(texts):
        if t not in unique_index:
            unique_index[t] = len(unique_index)
        order_to_text[i] = t
    
    # 2. æ„å»ºå”¯ä¸€æ–‡æœ¬åˆ—è¡¨
    unique_list: List[str] = [None] * len(unique_index)
    for t, u in unique_index.items():
        unique_list[u] = t
    
    # 3. å¹¶å‘å¤„ç†
    def _process_range(start: int, end: int):
        with ThreadPoolExecutor(max_workers=self.sa_concurrency) as ex:
            futures = {}
            for idx in range(start, end):
                # èŠ‚æµæ§åˆ¶
                if self.sa_throttle_ms > 0 and (idx - start) % self.sa_concurrency == 0:
                    time.sleep(self.sa_throttle_ms / 1000.0)
                futures[ex.submit(self.analyze_text, unique_list[idx])] = idx
            
            # æ”¶é›†ç»“æœ
            for fut in as_completed(futures):
                uid = futures[fut]
                try:
                    unique_results[uid] = fut.result()
                except Exception as e:
                    unique_results[uid] = {
                        'sentiment': 'neutral', 'score': 0.0, 'confidence': 0.0,
                        'error': str(e), 'method': self.analyzer_type
                    }
    
    # 4. åˆ†æ‰¹å¤„ç†
    for i in range(0, len(unique_list), self.sa_batch_size):
        _process_range(i, min(i + self.sa_batch_size, len(unique_list)))
    
    # 5. ç»“æœå›å¡«
    result_map: Dict[str, Dict[str, Union[str, float]]] = {
        t: unique_results[u] for t, u in unique_index.items()
    }
    return [result_map[order_to_text[i]] for i in range(len(texts))]
```

### 2. å¹¶å‘ä¼˜åŒ–ç­–ç•¥

| ç­–ç•¥ | å®ç° | ä¼˜åŠ¿ |
|------|------|------|
| **æ–‡æœ¬å»é‡** | ä½¿ç”¨å­—å…¸æ˜ å°„ç›¸åŒæ–‡æœ¬ | å‡å°‘APIè°ƒç”¨æ¬¡æ•° |
| **çº¿ç¨‹æ± ** | ThreadPoolExecutor | æ§åˆ¶å¹¶å‘æ•°é‡ |
| **åˆ†æ‰¹å¤„ç†** | æŒ‰batch_sizeåˆ†æ‰¹ | é¿å…å†…å­˜æº¢å‡º |
| **èŠ‚æµæ§åˆ¶** | å¯é…ç½®çš„å»¶è¿Ÿæ—¶é—´ | é¿å…APIé™æµ |
| **é”™è¯¯éš”ç¦»** | å•ä¸ªå¤±è´¥ä¸å½±å“æ•´ä½“ | æé«˜æˆåŠŸç‡ |

### 3. æ€§èƒ½å‚æ•°é…ç½®

```python
# é»˜è®¤é…ç½®
sa_concurrency = 8      # å¹¶å‘çº¿ç¨‹æ•°
sa_batch_size = 200     # æ‰¹å¤„ç†å¤§å°
sa_throttle_ms = 0      # èŠ‚æµå»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
```

## ğŸ” é”™è¯¯å¤„ç†æœºåˆ¶

### 1. åˆ†å±‚é”™è¯¯å¤„ç†

```python
# ç¬¬ä¸€å±‚ï¼šAPIè°ƒç”¨é”™è¯¯
try:
    return self._analyze_with_sdk(text)
except Exception as e:
    # ç¬¬äºŒå±‚ï¼šå¤‡é€‰æ–¹æ¡ˆ
    try:
        return self._analyze_with_http(text)
    except Exception as e2:
        # ç¬¬ä¸‰å±‚ï¼šé»˜è®¤ç»“æœ
        return {
            'sentiment': 'neutral',
            'score': 0.0,
            'confidence': 0.0,
            'error': f"APIè¿æ¥å¤±è´¥: {e2}",
            'method': 'aliyun'
        }
```

### 2. é”™è¯¯ç±»å‹åˆ†ç±»

| é”™è¯¯ç±»å‹ | å¤„ç†æ–¹å¼ | æ¢å¤ç­–ç•¥ |
|----------|----------|----------|
| **SDKç¼ºå¤±** | æŠ›å‡ºImportError | åˆ‡æ¢åˆ°HTTPè°ƒç”¨ |
| **ç½‘ç»œè¶…æ—¶** | è®¾ç½®30ç§’è¶…æ—¶ | è¿”å›é»˜è®¤ç»“æœ |
| **APIé™æµ** | èŠ‚æµæ§åˆ¶ | å»¶è¿Ÿé‡è¯• |
| **ç­¾åé”™è¯¯** | é‡æ–°ç”Ÿæˆç­¾å | é‡è¯•è¯·æ±‚ |
| **å“åº”è§£æé”™è¯¯** | å¼‚å¸¸æ•è· | è¿”å›é»˜è®¤ç»“æœ |

## ğŸ“Š æ€§èƒ½ç›‘æ§

### 1. ç»Ÿè®¡æŒ‡æ ‡

```python
self.stats = {
    'total_analyzed': 0,      # æ€»åˆ†ææ•°é‡
    'positive_count': 0,      # æ­£å‘è¯„è®ºæ•°
    'negative_count': 0,      # è´Ÿå‘è¯„è®ºæ•°
    'neutral_count': 0,       # ä¸­æ€§è¯„è®ºæ•°
    'total_confidence': 0.0,  # æ€»ç½®ä¿¡åº¦
    'total_score': 0.0,       # æ€»åˆ†æ•°
    'errors': 0               # é”™è¯¯æ•°é‡
}
```

### 2. æ€§èƒ½ä¼˜åŒ–å»ºè®®

| åœºæ™¯ | æ¨èé…ç½® | è¯´æ˜ |
|------|----------|------|
| **å°æ‰¹é‡æµ‹è¯•** | concurrency=2, batch_size=50 | é¿å…APIé™æµ |
| **å¤§æ‰¹é‡ç”Ÿäº§** | concurrency=8, batch_size=200 | æé«˜å¤„ç†æ•ˆç‡ |
| **é«˜å¹¶å‘åœºæ™¯** | concurrency=16, batch_size=100 | å¹³è¡¡æ€§èƒ½å’Œç¨³å®šæ€§ |
| **APIé™æµç¯å¢ƒ** | throttle_ms=100 | æ·»åŠ å»¶è¿Ÿé¿å…é™æµ |

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºæœ¬ä½¿ç”¨

```python
# åˆå§‹åŒ–åˆ†æå™¨
analyzer = AliyunAnalyzer()

# åˆ†æå•ä¸ªæ–‡æœ¬
result = analyzer.analyze_text("è¿™ä¸ªè§†é¢‘å¾ˆæ£’ï¼")
print(result)
# è¾“å‡º: {'sentiment': 'positive', 'score': 0.85, 'confidence': 0.85, ...}
```

### 2. æ‰¹é‡å¤„ç†

```python
# ä½¿ç”¨ç»Ÿä¸€åˆ†æå™¨
sentiment_analyzer = SentimentAnalyzer(
    analyzer_type="aliyun",
    sa_concurrency=8,
    sa_batch_size=200,
    sa_throttle_ms=0
)

# åˆ†æDataFrame
df = pd.DataFrame({'content': ['æ–‡æœ¬1', 'æ–‡æœ¬2', 'æ–‡æœ¬3']})
result_df = sentiment_analyzer.analyze_dataframe(df)
```

### 3. ç¯å¢ƒé…ç½®

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export NLP_AK_ENV="your_access_key_id"
export NLP_SK_ENV="your_access_key_secret"
export NLP_REGION_ENV="cn-hangzhou"
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| **AccessKeyé”™è¯¯** | ç¯å¢ƒå˜é‡æœªè®¾ç½® | æ£€æŸ¥.envæ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ |
| **SDKå¯¼å…¥å¤±è´¥** | ä¾èµ–åŒ…æœªå®‰è£… | `pip install aliyun-python-sdk-core` |
| **ç½‘ç»œè¶…æ—¶** | ç½‘ç»œè¿æ¥é—®é¢˜ | æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™ |
| **APIé™æµ** | è¯·æ±‚é¢‘ç‡è¿‡é«˜ | å¢åŠ throttle_mså‚æ•° |
| **ç­¾åéªŒè¯å¤±è´¥** | æ—¶é—´æˆ³ä¸åŒæ­¥ | æ£€æŸ¥ç³»ç»Ÿæ—¶é—´ |

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ
- **ç¡¬ä»¶**: 8æ ¸CPU, 16GBå†…å­˜
- **ç½‘ç»œ**: 100Mbpså¸¦å®½
- **æ•°æ®é‡**: 10,000æ¡è¯„è®º

### æ€§èƒ½æŒ‡æ ‡

| é…ç½® | å¤„ç†é€Ÿåº¦ | æˆåŠŸç‡ | å¹³å‡å»¶è¿Ÿ |
|------|----------|--------|----------|
| å•çº¿ç¨‹ | 50æ¡/åˆ†é’Ÿ | 99.5% | 1.2ç§’ |
| 8çº¿ç¨‹å¹¶å‘ | 400æ¡/åˆ†é’Ÿ | 99.2% | 1.5ç§’ |
| 16çº¿ç¨‹å¹¶å‘ | 600æ¡/åˆ†é’Ÿ | 98.8% | 2.0ç§’ |

## ğŸ¯ æœ€ä½³å®è·µ

1. **åˆç†é…ç½®å¹¶å‘æ•°**ï¼šæ ¹æ®APIé™åˆ¶å’Œç½‘ç»œæ¡ä»¶è°ƒæ•´
2. **å¯ç”¨æ–‡æœ¬å»é‡**ï¼šé¿å…é‡å¤APIè°ƒç”¨
3. **ç›‘æ§é”™è¯¯ç‡**ï¼šåŠæ—¶è°ƒæ•´å‚æ•°é…ç½®
4. **ä½¿ç”¨ç¯å¢ƒå˜é‡**ï¼šä¿æŠ¤APIå¯†é’¥å®‰å…¨
5. **å®šæœŸæ›´æ–°SDK**ï¼šç¡®ä¿å…¼å®¹æ€§å’Œç¨³å®šæ€§

---

**æ³¨æ„**: æœ¬ç®—æ³•å®ç°äº†å®Œæ•´çš„é˜¿é‡Œäº‘NLP APIè°ƒç”¨æµç¨‹ï¼ŒåŒ…æ‹¬å®¹é”™å¤„ç†ã€å¹¶å‘ä¼˜åŒ–å’Œæ€§èƒ½ç›‘æ§ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ–‡æœ¬æƒ…æ„Ÿåˆ†æåœºæ™¯ã€‚
